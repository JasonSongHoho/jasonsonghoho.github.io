<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>jason&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://jasonsonghoho.github.io/"/>
  <updated>2018-09-22T02:33:29.034Z</updated>
  <id>https://jasonsonghoho.github.io/</id>
  
  <author>
    <name>jason song</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Java 7 HashMap 源码解读</title>
    <link href="https://jasonsonghoho.github.io/2018/08/18/Java-7-HashMap-%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
    <id>https://jasonsonghoho.github.io/2018/08/18/Java-7-HashMap-源码解读/</id>
    <published>2018-08-18T02:31:46.000Z</published>
    <updated>2018-09-22T02:33:29.034Z</updated>
    
    <content type="html"><![CDATA[<p>见链接：<a href="https://mp.weixin.qq.com/s/nHk9jKapNVVkBDnKChgK0Q" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/nHk9jKapNVVkBDnKChgK0Q</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;见链接：&lt;a href=&quot;https://mp.weixin.qq.com/s/nHk9jKapNVVkBDnKChgK0Q&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/nHk9jKapNVVkBDn
      
    
    </summary>
    
      <category term="Java" scheme="https://jasonsonghoho.github.io/categories/Java/"/>
    
    
      <category term="公众号文章" scheme="https://jasonsonghoho.github.io/public/tags/%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0/"/>
    
      <category term="Java" scheme="https://jasonsonghoho.github.io/public/tags/Java/"/>
    
      <category term="HashMap" scheme="https://jasonsonghoho.github.io/public/tags/HashMap/"/>
    
  </entry>
  
  <entry>
    <title>React快速入门</title>
    <link href="https://jasonsonghoho.github.io/2018/06/24/React%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"/>
    <id>https://jasonsonghoho.github.io/2018/06/24/React快速入门/</id>
    <published>2018-06-24T02:34:27.000Z</published>
    <updated>2018-09-22T02:52:12.539Z</updated>
    
    <content type="html"><![CDATA[<p>见链接：<a href="https://mp.weixin.qq.com/s/fDXQe_QCBN4q6zfzKQr1jQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/fDXQe_QCBN4q6zfzKQr1jQ</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;见链接：&lt;a href=&quot;https://mp.weixin.qq.com/s/fDXQe_QCBN4q6zfzKQr1jQ&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/fDXQe_QCBN4q6zf
      
    
    </summary>
    
      <category term="前端" scheme="https://jasonsonghoho.github.io/categories/%E5%89%8D%E7%AB%AF/"/>
    
    
      <category term="公众号文章" scheme="https://jasonsonghoho.github.io/public/tags/%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0/"/>
    
      <category term="React" scheme="https://jasonsonghoho.github.io/public/tags/React/"/>
    
  </entry>
  
  <entry>
    <title>动物园管理员——ZooKeeper</title>
    <link href="https://jasonsonghoho.github.io/2018/06/05/%E5%8A%A8%E7%89%A9%E5%9B%AD%E7%AE%A1%E7%90%86%E5%91%98%E2%80%94%E2%80%94ZooKeeper/"/>
    <id>https://jasonsonghoho.github.io/2018/06/05/动物园管理员——ZooKeeper/</id>
    <published>2018-06-05T02:35:00.000Z</published>
    <updated>2018-09-22T02:52:12.560Z</updated>
    
    <content type="html"><![CDATA[<p>见链接：<a href="https://mp.weixin.qq.com/s/hnfWq1sHD8qxKoXHKwJhiw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/hnfWq1sHD8qxKoXHKwJhiw</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;见链接：&lt;a href=&quot;https://mp.weixin.qq.com/s/hnfWq1sHD8qxKoXHKwJhiw&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/hnfWq1sHD8qxKoX
      
    
    </summary>
    
      <category term="中间件" scheme="https://jasonsonghoho.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
      <category term="公众号文章" scheme="https://jasonsonghoho.github.io/public/tags/%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0/"/>
    
      <category term="ZooKeeper" scheme="https://jasonsonghoho.github.io/public/tags/ZooKeeper/"/>
    
  </entry>
  
  <entry>
    <title>MySQL究竟如何解决“不可重复读”和“幻读”的</title>
    <link href="https://jasonsonghoho.github.io/2018/05/27/MySQL%E7%A9%B6%E7%AB%9F%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E2%80%9C%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB%E2%80%9D%E5%92%8C%E2%80%9C%E5%B9%BB%E8%AF%BB%E2%80%9D%E7%9A%84/"/>
    <id>https://jasonsonghoho.github.io/2018/05/27/MySQL究竟如何解决“不可重复读”和“幻读”的/</id>
    <published>2018-05-26T16:35:44.000Z</published>
    <updated>2018-09-22T02:30:44.066Z</updated>
    
    <content type="html"><![CDATA[<p>见链接：<a href="https://mp.weixin.qq.com/s/Ej3coEuouPqbzkL0-J8tIQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/Ej3coEuouPqbzkL0-J8tIQ</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;见链接：&lt;a href=&quot;https://mp.weixin.qq.com/s/Ej3coEuouPqbzkL0-J8tIQ&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/Ej3coEuouPqbzkL
      
    
    </summary>
    
      <category term="数据库" scheme="https://jasonsonghoho.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="公众号文章" scheme="https://jasonsonghoho.github.io/public/tags/%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0/"/>
    
      <category term="mysql" scheme="https://jasonsonghoho.github.io/public/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>我们为提升 Cassandra 读性能做了哪些努力？</title>
    <link href="https://jasonsonghoho.github.io/2018/05/21/180521/"/>
    <id>https://jasonsonghoho.github.io/2018/05/21/180521/</id>
    <published>2018-05-21T14:08:41.000Z</published>
    <updated>2018-09-20T15:23:28.340Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录-Table-of-Contents"><a href="#目录-Table-of-Contents" class="headerlink" title=" 目录 (Table of Contents)"></a> <strong>目录 (Table of Contents)</strong></h2><ul><li>关于Cassandra</li><li>提升读性能</li></ul><h2 id="关于Cassandra"><a href="#关于Cassandra" class="headerlink" title="关于Cassandra"></a>关于Cassandra</h2><p>Apache Cassandra是一个高度可扩展的高性能分布式数据库，<br>用于处理大量常规服务器上的大量数据，提供高可用性，无单点故障。它是一种NoSQL类型的数据库。</p><p>我们看一下国外权威机构<a href="https://db-engines.com/en/ranking" target="_blank" rel="noopener">DB-Engines</a>最近的数据库全球流行程度排名：</p><img src="/2018/05/21/180521/database_rank.png" title="数据库排名"><p>可以看出，Cassandra 是排名前十中四个仅有的NoSQL数据库之一。Cassandra在国外这样受欢迎，其性能可想而知不会差，<br>但是在国内貌似还没有多少公司使用，且国内关于 Cassandra方面的资料较少。</p><h2 id="提升读性能"><a href="#提升读性能" class="headerlink" title="提升读性能"></a>提升读性能</h2><p>Cassandra 在我们的项目中用来存储时序数据，经过测试，在三台4核16G的虚拟机上，<br>指标数据的写入TPS可以达到6.5W/s，基本可以满足我们的业务需求。<br>但是读取性能可能就会差很多，因为数据查询速度跟每次查询的数据量关系比较大，此处也不好定义TPS。<br>产品查询一周以上的指标数据时，经常会出现加载缓慢，甚至查询超时。为了改善查询状况，我们进行了不少努力。</p><p>此处不讨论纵向扩展和横向扩展带来的性能提升。</p><h3 id="1-加快墓碑回收甚至去除墓碑"><a href="#1-加快墓碑回收甚至去除墓碑" class="headerlink" title="1. 加快墓碑回收甚至去除墓碑"></a>1. 加快墓碑回收甚至去除墓碑</h3><p>在Cassandra中，当你删除一条数据时，其实是给这条数据进行update，给它update上一个标识，就是一个墓碑标识。<br> 当Cassandra集群在不同节点之间同步删除信息的时候，也会用到Tombstones(墓碑)，可以说墓碑是一种允许Cassandra快速写入的机制。</p><p>关于墓碑的更多消息，可参考 <a href="https://docs.datastax.com/en/Cassandra/3.0/Cassandra/dml/dmlHowDataMaintain.html" target="_blank" rel="noopener">Cassandra 数据维护官方文档</a></p><p>可以这样理解，大量的墓碑数据会使查询时搜索的数据量变大，直接影响查询时的效率。<br>所以，为了消除这种影响，我们可以加快墓碑数据的回收，避免产生大量的墓碑数据。<br>甚至，当我们在写入时，若写入一致性的值与副本因子数量相等时，可以不产生墓碑数据，直接删掉该无效数据。<br>具体可通过 调整 table 中 gc_grace_seconds 参数来实现，默认为 864000（10天），我们可以设为 86400（1天）或者0（直接删除）。</p><h3 id="2-降低read-repair-的几率"><a href="#2-降低read-repair-的几率" class="headerlink" title="2. 降低read repair 的几率"></a>2. 降低read repair 的几率</h3><p>每一次读操作，Cassandra都会在后台进行read repair操作。<br>如果只要求读一个节点数据，Cassandra在读到一个节点后，就将结果返回客户端，<br>然后用read repair对其他的replicas进行同步（根据timestamp）。<br>如果要求读多个节点，那么Cassandra就读多个节点，然后根据timestamp进行比较，返回客户端最新的数据，<br>然后再调用read repair对其他节点进行同步。<br>Read repair在后台的操作，会占用一定的CPU和I/O,所以影响读性能。<br>我们可以降低read repair 的几率，以提高读取性能。</p><p>通过修改 table 中 read_repair_chance（取值范围 0-1）参数来设置read repair 的几率，建议设为 0.1。</p><h3 id="3-指标数据预聚合"><a href="#3-指标数据预聚合" class="headerlink" title="3. 指标数据预聚合"></a>3. 指标数据预聚合</h3><p>思路：我们存在数据库中的指标数据，读取时会将指定时间范围内的数据进行聚合。<br>如果提前将数据按基本时间段提前聚合为一个值，读取时，只读取时间范围内的时间段的汇聚结果，将大大减少查询耗时。</p><h3 id="4-合理部署产品"><a href="#4-合理部署产品" class="headerlink" title="4. 合理部署产品"></a>4. 合理部署产品</h3><p>公司的其他产品使用了mongoDB，线上环境中发现，这两个NoSQL数据库部署在一起时会相互争夺内存资源，<br>十分影响性能，因此最好将这两个数据库分开部署。</p><h3 id="5-设置合理的堆内存大小和GC策略"><a href="#5-设置合理的堆内存大小和GC策略" class="headerlink" title="5. 设置合理的堆内存大小和GC策略"></a>5. 设置合理的堆内存大小和GC策略</h3><p>堆内存设置的太小，将导致频繁GC甚至OOM，设置的太大同样也不好。可参考官方的公式:<br><code>MAX_HEAP_SIZE=max(min(1/2 ram, 1024MB), min(1/4 ram, 8GB)</code></p><p>关于GC策略，官方的建议是：小于16G，用CMS收集器；16-64G，用G1收集器。</p><h3 id="6-设置合理的压式策略"><a href="#6-设置合理的压式策略" class="headerlink" title="6. 设置合理的压式策略"></a>6. 设置合理的压式策略</h3><p>Cassandra 将落到磁盘的数据存放在SStable中，压实是将多个SSTable 文件合并为一个的过程。合并后将减少重复的数据，使数据更紧凑。<br>Cassandra 有多种触发压实的策略，选一个适合的压实策略，可以更好地压实数据。<br>比如，我们使用的Kairosdb建议采用 DateTieredCompactionStrategy (<a href="https://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlHowDataMaintain.html#dmlHowDataMaintain__dtcs-compaction" target="_blank" rel="noopener">DTCS</a>))压实策略。</p><h3 id="7-启用-row-cache"><a href="#7-启用-row-cache" class="headerlink" title="7. 启用 row cache"></a>7. 启用 row cache</h3><p>row cache 把整个row 的内容都放在内存中。<br>适合的情况是，有一小部分hot data是经常反问的，或者要返回整个columns.在使用row cache时，用注意它对内存的影响。<br>可参考 Cassandra 的<a href="https://docs.datastax.com/en/cassandra/3.0/cassandra/operations/opsConfiguringCaches.html" target="_blank" rel="noopener">官方文档</a>设置row cache。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>安利一个入门Cassandra 的好博客：<a href="http://teddymaef.github.io/learnCassandra/cn/" target="_blank" rel="noopener">learn Cassandra</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录-Table-of-Contents&quot;&gt;&lt;a href=&quot;#目录-Table-of-Contents&quot; class=&quot;headerlink&quot; title=&quot; 目录 (Table of Contents)&quot;&gt;&lt;/a&gt; &lt;strong&gt;目录 (Table of C
      
    
    </summary>
    
      <category term="数据库" scheme="https://jasonsonghoho.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="cassandra" scheme="https://jasonsonghoho.github.io/public/tags/cassandra/"/>
    
      <category term="大数据" scheme="https://jasonsonghoho.github.io/public/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Linux中的top命令详解</title>
    <link href="https://jasonsonghoho.github.io/2018/05/20/Linux%E4%B8%AD%E7%9A%84top%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3/"/>
    <id>https://jasonsonghoho.github.io/2018/05/20/Linux中的top命令详解/</id>
    <published>2018-05-20T02:41:23.000Z</published>
    <updated>2018-09-22T02:52:12.563Z</updated>
    
    <content type="html"><![CDATA[<p>见链接：<a href="https://mp.weixin.qq.com/s/xyYn6xaahQ4hv1y9MM-7JA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/xyYn6xaahQ4hv1y9MM-7JA</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;见链接：&lt;a href=&quot;https://mp.weixin.qq.com/s/xyYn6xaahQ4hv1y9MM-7JA&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/xyYn6xaahQ4hv1y
      
    
    </summary>
    
      <category term="Linux" scheme="https://jasonsonghoho.github.io/categories/Linux/"/>
    
    
      <category term="公众号文章" scheme="https://jasonsonghoho.github.io/public/tags/%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0/"/>
    
      <category term="Linux" scheme="https://jasonsonghoho.github.io/public/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Linux 的 Cache、Buffer、MemAvailable、Swap简介</title>
    <link href="https://jasonsonghoho.github.io/2018/05/20/Linux-%E7%9A%84-Cache%E3%80%81Buffer%E3%80%81MemAvailable%E3%80%81Swap%E7%AE%80%E4%BB%8B/"/>
    <id>https://jasonsonghoho.github.io/2018/05/20/Linux-的-Cache、Buffer、MemAvailable、Swap简介/</id>
    <published>2018-05-20T02:40:08.000Z</published>
    <updated>2018-09-22T02:52:12.543Z</updated>
    
    <content type="html"><![CDATA[<p>见链接：<a href="https://mp.weixin.qq.com/s/59oH1hMMXy6YC618gZkm1g" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/59oH1hMMXy6YC618gZkm1g</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;见链接：&lt;a href=&quot;https://mp.weixin.qq.com/s/59oH1hMMXy6YC618gZkm1g&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/59oH1hMMXy6YC61
      
    
    </summary>
    
      <category term="Linux" scheme="https://jasonsonghoho.github.io/categories/Linux/"/>
    
    
      <category term="公众号文章" scheme="https://jasonsonghoho.github.io/public/tags/%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0/"/>
    
      <category term="Linux" scheme="https://jasonsonghoho.github.io/public/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>克拉丝的面试</title>
    <link href="https://jasonsonghoho.github.io/2018/05/13/%E5%85%8B%E6%8B%89%E4%B8%9D%E7%9A%84%E9%9D%A2%E8%AF%95/"/>
    <id>https://jasonsonghoho.github.io/2018/05/13/克拉丝的面试/</id>
    <published>2018-05-13T02:39:39.000Z</published>
    <updated>2018-09-22T02:52:46.942Z</updated>
    
    <content type="html"><![CDATA[<p>见链接：<a href="https://mp.weixin.qq.com/s/boQUsfwjf0pPtcU_mAUWbA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/boQUsfwjf0pPtcU_mAUWbA</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;见链接：&lt;a href=&quot;https://mp.weixin.qq.com/s/boQUsfwjf0pPtcU_mAUWbA&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/boQUsfwjf0pPtcU
      
    
    </summary>
    
      <category term="Java" scheme="https://jasonsonghoho.github.io/categories/Java/"/>
    
    
      <category term="公众号文章" scheme="https://jasonsonghoho.github.io/public/tags/%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0/"/>
    
      <category term="JVM" scheme="https://jasonsonghoho.github.io/public/tags/JVM/"/>
    
      <category term="类加载" scheme="https://jasonsonghoho.github.io/public/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>工厂模式、简单工厂模式与抽象工厂模式</title>
    <link href="https://jasonsonghoho.github.io/2018/05/10/%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E3%80%81%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E4%B8%8E%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"/>
    <id>https://jasonsonghoho.github.io/2018/05/10/工厂模式、简单工厂模式与抽象工厂模式/</id>
    <published>2018-05-10T02:39:16.000Z</published>
    <updated>2018-09-22T02:52:12.556Z</updated>
    
    <content type="html"><![CDATA[<p>见链接：<a href="https://mp.weixin.qq.com/s/ccNz_veqyb4UYBpH-UpZfA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/ccNz_veqyb4UYBpH-UpZfA</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;见链接：&lt;a href=&quot;https://mp.weixin.qq.com/s/ccNz_veqyb4UYBpH-UpZfA&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/ccNz_veqyb4UYBp
      
    
    </summary>
    
      <category term="设计模式" scheme="https://jasonsonghoho.github.io/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
    
      <category term="公众号文章" scheme="https://jasonsonghoho.github.io/public/tags/%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0/"/>
    
      <category term="设计模式" scheme="https://jasonsonghoho.github.io/public/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>园丁与盆栽（JVM 垃圾回收）</title>
    <link href="https://jasonsonghoho.github.io/2018/05/01/%E5%9B%AD%E4%B8%81%E4%B8%8E%E7%9B%86%E6%A0%BD/"/>
    <id>https://jasonsonghoho.github.io/2018/05/01/园丁与盆栽/</id>
    <published>2018-05-01T02:38:55.000Z</published>
    <updated>2018-09-22T02:52:12.553Z</updated>
    
    <content type="html"><![CDATA[<p>见链接：<a href="https://mp.weixin.qq.com/s/2GO3Sc4mD8BVN3PnfJQixg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/2GO3Sc4mD8BVN3PnfJQixg</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;见链接：&lt;a href=&quot;https://mp.weixin.qq.com/s/2GO3Sc4mD8BVN3PnfJQixg&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/2GO3Sc4mD8BVN3P
      
    
    </summary>
    
      <category term="Java" scheme="https://jasonsonghoho.github.io/categories/Java/"/>
    
    
      <category term="公众号文章" scheme="https://jasonsonghoho.github.io/public/tags/%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0/"/>
    
      <category term="JVM" scheme="https://jasonsonghoho.github.io/public/tags/JVM/"/>
    
      <category term="GC" scheme="https://jasonsonghoho.github.io/public/tags/GC/"/>
    
  </entry>
  
  <entry>
    <title>克拉丝的JVM工厂之旅（上）</title>
    <link href="https://jasonsonghoho.github.io/2018/04/15/%E5%85%8B%E6%8B%89%E4%B8%9D%E7%9A%84JVM%E5%B7%A5%E5%8E%82%E4%B9%8B%E6%97%85%EF%BC%88%E4%B8%8A%EF%BC%89/"/>
    <id>https://jasonsonghoho.github.io/2018/04/15/克拉丝的JVM工厂之旅（上）/</id>
    <published>2018-04-15T02:37:32.000Z</published>
    <updated>2018-09-22T02:52:12.549Z</updated>
    
    <content type="html"><![CDATA[<p>见链接：<a href="https://mp.weixin.qq.com/s/X_tO5Lgjof_RTlyN_xtSHw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/X_tO5Lgjof_RTlyN_xtSHw</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;见链接：&lt;a href=&quot;https://mp.weixin.qq.com/s/X_tO5Lgjof_RTlyN_xtSHw&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://mp.weixin.qq.com/s/X_tO5Lgjof_RTly
      
    
    </summary>
    
      <category term="Java" scheme="https://jasonsonghoho.github.io/categories/Java/"/>
    
    
      <category term="公众号文章" scheme="https://jasonsonghoho.github.io/public/tags/%E5%85%AC%E4%BC%97%E5%8F%B7%E6%96%87%E7%AB%A0/"/>
    
      <category term="JVM" scheme="https://jasonsonghoho.github.io/public/tags/JVM/"/>
    
      <category term="类加载" scheme="https://jasonsonghoho.github.io/public/tags/%E7%B1%BB%E5%8A%A0%E8%BD%BD/"/>
    
  </entry>
  
  <entry>
    <title>Metric使用</title>
    <link href="https://jasonsonghoho.github.io/2017/12/18/2017-12-18-doc/"/>
    <id>https://jasonsonghoho.github.io/2017/12/18/2017-12-18-doc/</id>
    <published>2017-12-18T14:08:41.000Z</published>
    <updated>2018-09-22T02:49:05.202Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录-Table-of-Contents"><a href="#目录-Table-of-Contents" class="headerlink" title=" 目录 (Table of Contents)"></a> <strong>目录 (Table of Contents)</strong></h2><ul><li>简介</li><li>MAVEN设置</li><li>The Registry</li><li>五种度量类型<ul><li>Gauges</li><li>Counters</li><li>Histograms</li><li>Meters</li><li>Timers</li></ul></li><li>Reporter</li><li>健康检查</li></ul><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Metrics是一个给JAVA提供度量工具的包，在JAVA代码中嵌入Metrics代码，可以方便的对业务代码的各个指标进行监控。<br>Metric 的使用可参考<a href="http://metrics.dropwizard.io/3.2.3/getting-started.html" target="_blank" rel="noopener">官网</a>。</p><h2 id="MAVEN设置"><a href="#MAVEN设置" class="headerlink" title="MAVEN设置"></a>MAVEN设置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt; </span><br><span class="line">    &lt;dependency&gt; </span><br><span class="line">        &lt;groupId&gt; io.dropwizard.metrics &lt;/ groupId&gt; </span><br><span class="line">        &lt;artifactId&gt; metrics-core &lt;/ artifactId&gt; </span><br><span class="line">        &lt;version&gt; $ &#123;metrics.version&#125; &lt;/ version&gt; </span><br><span class="line">    &lt;/ dependency&gt; </span><br><span class="line">&lt;/ dependencies&gt;</span><br></pre></td></tr></table></figure><h2 id="The-Registry"><a href="#The-Registry" class="headerlink" title="The Registry"></a>The Registry</h2><p>Metrics的核心是MetricRegistry类，它是所有应用程序指标的容器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">final MetricRegistry metrics = new MetricRegistry();</span><br></pre></td></tr></table></figure><h2 id="五种度量类型"><a href="#五种度量类型" class="headerlink" title="五种度量类型"></a>五种度量类型</h2><h3 id="Gauges"><a href="#Gauges" class="headerlink" title="Gauges"></a>Gauges</h3><p>最基本的度量指标，返回一个值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public class QueueManager &#123;</span><br><span class="line">    private final Queue queue;</span><br><span class="line"></span><br><span class="line">    public QueueManager(MetricRegistry metrics, String name) &#123;</span><br><span class="line">        this.queue = new Queue();</span><br><span class="line">        metrics.register(MetricRegistry.name(QueueManager.class, name, &quot;size&quot;),</span><br><span class="line">                         new Gauge&lt;Integer&gt;() &#123;</span><br><span class="line">                             @Override</span><br><span class="line">                             public Integer getValue() &#123;</span><br><span class="line">                                 return queue.size();</span><br><span class="line">                             &#125;</span><br><span class="line">                         &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测量此量表时，将返回队列中的任务数量。</p><p>在注册表中的每个指标都有一个唯一的名称，例如 “things.count”或”com.example.Thing.latency”。MetricRegistry有一个用于构造这些名字的静态辅助方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MetricRegistry.name(QueueManager.class, &quot;jobs&quot;, &quot;size&quot;)</span><br></pre></td></tr></table></figure><p>它将返回一个类似”com.example.QueueManager.jobs.size”的字符串。</p><h3 id="Counters"><a href="#Counters" class="headerlink" title="Counters"></a>Counters</h3><p>Counters只是一个AtomicLong实例的衡量标准。您可以增加或减少其值。例如，我们可能需要一个更有效的方式来衡量队列中待处理的任务：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">private final Counter pendingJobs = metrics.counter(name(QueueManager.class, &quot;pending-jobs&quot;));</span><br><span class="line"></span><br><span class="line">public void addJob(Job job) &#123;</span><br><span class="line">    pendingJobs.inc();</span><br><span class="line">    queue.offer(job);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public Job takeJob() &#123;</span><br><span class="line">    pendingJobs.dec();</span><br><span class="line">    return queue.take();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>每次测量这个计数器时，它都会返回队列中的任务数量。</p><p>正如你所看到的，Counters的API略有不同：用 counter(String)而不是 register(String, Metric) 。</p><h3 id="Histograms"><a href="#Histograms" class="headerlink" title="Histograms"></a>Histograms</h3><p>Histograms（直方图 ）统计 数据流中值的分布。除了最小值，最大值，平均值等之外，它还测量中值，第75,90,95,98,99和99.9百分位数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">private final Histogram responseSizes = metrics.histogram(name(RequestHandler.class, &quot;response-sizes&quot;));</span><br><span class="line"></span><br><span class="line">public void handleRequest(Request request, Response response) &#123;</span><br><span class="line">    // etc</span><br><span class="line">    responseSizes.update(response.getContent().length);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个直方图将以字节为单位来测量响应的大小。</p><h3 id="Meters"><a href="#Meters" class="headerlink" title="Meters"></a>Meters</h3><p>Meters测量一段时间内的事件发生率（例如“每秒请求数”）。除了平均速度之外，Meters还跟踪1，5和15分钟的均值。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">private final MetricRegistry metrics = new MetricRegistry();</span><br><span class="line">private final Meter requests = metrics.meter(&quot;requests&quot;);</span><br><span class="line"></span><br><span class="line">public void handleRequest(Request request, Response response) &#123;</span><br><span class="line">    requests.mark();</span><br><span class="line">    // etc</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>将测量每秒请求的请求率。</p><h3 id="Timer"><a href="#Timer" class="headerlink" title="Timer"></a>Timer</h3><p>Timer测量一段代码被调用的速率和它的持续时间的分布。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">private final Timer responses = metrics.timer(name(RequestHandler.class, &quot;responses&quot;));</span><br><span class="line"></span><br><span class="line">public String handleRequest(Request request, Response response) &#123;</span><br><span class="line">    final Timer.Context context = responses.time(); //相当于Meter.mark()</span><br><span class="line">    try &#123;</span><br><span class="line">        // etc;</span><br><span class="line">        return &quot;OK&quot;;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        context.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该Timer 将测量处理每个请求所需的时间（以纳秒为单位），并提供每秒请求的请求速率。</p><p>Timer 其实是 Histogram 和 Meter 的结合</p><h2 id="Reporter"><a href="#Reporter" class="headerlink" title="Reporter"></a>Reporter</h2><p>报表，用于展示统计结果</p><ol><li><p>通过JMX报告Metric</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">final JmxReporter reporter = JmxReporter.forRegistry(registry).build();</span><br><span class="line">reporter.start();</span><br></pre></td></tr></table></figure></li><li><p>STDOUT, using ConsoleReporter from metrics-core</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">final ConsoleReporter reporter = ConsoleReporter.forRegistry(registry)</span><br><span class="line">                                                .convertRatesTo(TimeUnit.SECONDS)</span><br><span class="line">                                                .convertDurationsTo(TimeUnit.MILLISECONDS)</span><br><span class="line">                                                .build();</span><br><span class="line">reporter.start(1, TimeUnit.MINUTES);</span><br></pre></td></tr></table></figure></li><li><p>CSV files, using CsvReporter from metrics-core</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">final CsvReporter reporter = CsvReporter.forRegistry(registry)</span><br><span class="line">                                        .formatFor(Locale.US)</span><br><span class="line">                                        .convertRatesTo(TimeUnit.SECONDS)</span><br><span class="line">                                        .convertDurationsTo(TimeUnit.MILLISECONDS)</span><br><span class="line">                                        .build(new File(&quot;~/projects/data/&quot;));</span><br><span class="line">reporter.start(1, TimeUnit.SECONDS);</span><br></pre></td></tr></table></figure></li><li><p>SLF4J loggers, using Slf4jReporter from metrics-core</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">final Slf4jReporter reporter = Slf4jReporter.forRegistry(registry)</span><br><span class="line">                                            .outputTo(LoggerFactory.getLogger(&quot;com.example.metrics&quot;))</span><br><span class="line">                                            .convertRatesTo(TimeUnit.SECONDS)</span><br><span class="line">                                            .convertDurationsTo(TimeUnit.MILLISECONDS)</span><br><span class="line">                                            .build();</span><br><span class="line">reporter.start(1, TimeUnit.MINUTES);</span><br></pre></td></tr></table></figure></li><li><p>Ganglia, using GangliaReporter from metrics-ganglia</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">final GMetric ganglia = new GMetric(&quot;ganglia.example.com&quot;, 8649, UDPAddressingMode.MULTICAST, 1);</span><br><span class="line">final GangliaReporter reporter = GangliaReporter.forRegistry(registry)</span><br><span class="line">                                                .convertRatesTo(TimeUnit.SECONDS)</span><br><span class="line">                                                .convertDurationsTo(TimeUnit.MILLISECONDS)</span><br><span class="line">                                                .build(ganglia);</span><br><span class="line">reporter.start(1, TimeUnit.MINUTES);</span><br></pre></td></tr></table></figure></li><li><p>Graphite, using GraphiteReporter from metrics-graphite</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">final Graphite graphite = new Graphite(new InetSocketAddress(&quot;graphite.example.com&quot;, 2003));</span><br><span class="line">final GraphiteReporter reporter = GraphiteReporter.forRegistry(registry)</span><br><span class="line">                                                  .prefixedWith(&quot;web1.example.com&quot;)</span><br><span class="line">                                                  .convertRatesTo(TimeUnit.SECONDS)</span><br><span class="line">                                                  .convertDurationsTo(TimeUnit.MILLISECONDS)</span><br><span class="line">                                                  .filter(MetricFilter.ALL)</span><br><span class="line">                                                  .build(graphite);</span><br><span class="line">reporter.start(1, TimeUnit.MINUTES);</span><br></pre></td></tr></table></figure></li></ol><h2 id="健康检查"><a href="#健康检查" class="headerlink" title="健康检查"></a>健康检查</h2><p>度量标准还能够对服务的健康状况进行检查，需要引用metrics-healthchecks模块 。</p><p>首先，创建一个新的HealthCheckRegistry实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">final HealthCheckRegistry healthChecks = new HealthCheckRegistry();</span><br></pre></td></tr></table></figure><p>其次，实现一个HealthCheck子类：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public class DatabaseHealthCheck extends HealthCheck &#123;</span><br><span class="line">    private final Database database;</span><br><span class="line"></span><br><span class="line">    public DatabaseHealthCheck(Database database) &#123;</span><br><span class="line">        this.database = database;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public HealthCheck.Result check() throws Exception &#123;</span><br><span class="line">        if (database.isConnected()) &#123;</span><br><span class="line">            return HealthCheck.Result.healthy();</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            return HealthCheck.Result.unhealthy(&quot;Cannot connect to &quot; + database.getUrl());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后用Metrics注册它的一个实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">healthChecks.register(&quot;postgres&quot;, new DatabaseHealthCheck(database));</span><br></pre></td></tr></table></figure><p>运行所有注册的健康检查：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">final Map&lt;String, HealthCheck.Result&gt; results = healthChecks.runHealthChecks();</span><br><span class="line">for (Entry&lt;String, HealthCheck.Result&gt; entry : results.entrySet()) &#123;</span><br><span class="line">    if (entry.getValue().isHealthy()) &#123;</span><br><span class="line">        System.out.println(entry.getKey() + &quot; is healthy&quot;);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        System.err.println(entry.getKey() + &quot; is UNHEALTHY: &quot; + entry.getValue().getMessage());</span><br><span class="line">        final Throwable e = entry.getValue().getError();</span><br><span class="line">        if (e != null) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>度量标准带有预先构建的运行状况检查：ThreadDeadlockHealthCheck使用Java的内置线程死锁检测来确定是否有线程死锁。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录-Table-of-Contents&quot;&gt;&lt;a href=&quot;#目录-Table-of-Contents&quot; class=&quot;headerlink&quot; title=&quot; 目录 (Table of Contents)&quot;&gt;&lt;/a&gt; &lt;strong&gt;目录 (Table of C
      
    
    </summary>
    
      <category term="中间件" scheme="https://jasonsonghoho.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
      <category term="java" scheme="https://jasonsonghoho.github.io/public/tags/java/"/>
    
      <category term="Metric" scheme="https://jasonsonghoho.github.io/public/tags/Metric/"/>
    
  </entry>
  
  <entry>
    <title>产品性能自测</title>
    <link href="https://jasonsonghoho.github.io/2017/12/10/171210/"/>
    <id>https://jasonsonghoho.github.io/2017/12/10/171210/</id>
    <published>2017-12-10T14:08:41.000Z</published>
    <updated>2018-09-22T02:46:04.906Z</updated>
    
    <content type="html"><![CDATA[<p>*本文是从公司内网KB转过来的，格式有点混乱懒得改了QAZ~~</p><h2 id="目录-Table-of-Contents"><a href="#目录-Table-of-Contents" class="headerlink" title=" 目录 (Table of Contents)"></a> <strong>目录 (Table of Contents)</strong></h2><ul><li>FAQ</li><li>一、测试目的</li><li>二、测试环境</li><li>三、测试方法</li><li>四、测试结果<ul><li>写:</li><li>读：</li></ul></li><li>五、结论<ul><li>1、指标库写性能：</li><li>2、指标库读性能：</li></ul></li></ul><p></p><h2 id="id-指标库性能测试-FAQ">FAQ</h2><p></p><p><strong>1.写入能力：多少个15秒监控周期的主机，或180秒监控周期的网络设备的数据写入</strong></p><br><p style="margin-left: 30.0px;">假设现场1个资源每15 S上报100个指标，则每分钟上报400个，</p><br><p style="margin-left: 30.0px;">若部署单节点Cassandra，在redis集群状况良好的情况下，每分钟可写入80W个指标，可支持800000/400=2000个资源左右;</p><br><p style="margin-left: 30.0px;">若部署Cassandra 集群，每分钟可写入110W个指标，可支持1100000/400=2750个资源左右;</p><br><p style="margin-left: 30.0px;">考虑到稳定性可酌情减少资源量或增加配置。</p><br><p><strong>2.读出能力：每秒完成指定数据点数查询的TPS性能峰值，以便预测可以支持什么数量的仪表盘</strong></p><br><p style="margin-left: 30.0px;">在三台4C*16G的Cassandra节点的配置下，稳定查询的前提下，每分钟至少400条并发请求（每条请求至少6000条元数据，大约为15分钟的数据）。</p><br><p style="margin-left: 30.0px;"></p><br><p></p><br><p></p><br><p></p><br><h2 id="id-指标库性能测试-一、测试目的">一、测试目的</h2><br><p>测试在指定硬件条件下，指标库写入能力与读取能力。</p><br><h2 id="id-指标库性能测试-二、测试环境">二、测试环境</h2><br><div class="table-wrap"><br>    <table class="confluenceTable"><br>        <tbody><br>        <tr><br>            <th class="confluenceTh">ip</th><br>            <th colspan="1" class="confluenceTh">cpu</th><br>            <th class="confluenceTh">内存</th><br>            <th colspan="1" class="confluenceTh">磁盘</th><br>            <th colspan="1" class="confluenceTh">用途</th><br>            <th colspan="1" class="confluenceTh">备注</th><br>        </tr><br>        <tr><br>            <td colspan="1" class="confluenceTd">个人电脑</td><br>            <td colspan="1" class="confluenceTd">4核</td><br>            <td colspan="1" class="confluenceTd">16G</td><br>            <td colspan="1" class="confluenceTd"></td><br>            <td colspan="1" class="confluenceTd"><span>部署jmeter</span></td><br>            <td colspan="1" class="confluenceTd"></td><br>        </tr><br>        <tr><br>            <td colspan="1" class="confluenceTd"><span>10.1.53.37</span></td><br>            <td colspan="1" class="confluenceTd">6<span>核</span></td><br>            <td colspan="1" class="confluenceTd">8G</td><br>            <td colspan="1" class="confluenceTd"></td><br>            <td rowspan="4" class="confluenceTd">部署jmeter-server</td><br>            <td rowspan="4" class="confluenceTd"><p><span>通过jmeter来发送测试请求，</span></p><br>                <p>这些机器同时部署着其他产品。<br><br></p></td><br>        </tr><br>        <tr><br>            <td colspan="1" class="confluenceTd"><span>10.1.53.38</span></td><br>            <td colspan="1" class="confluenceTd"><span>4核</span></td><br>            <td colspan="1" class="confluenceTd">16G</td><br>            <td colspan="1" class="confluenceTd"></td><br>        </tr><br>        <tr><br>            <td colspan="1" class="confluenceTd"><span>10.1.53.65</span></td><br>            <td colspan="1" class="confluenceTd"><span>4核</span></td><br>            <td colspan="1" class="confluenceTd"><span>8G</span></td><br>            <td colspan="1" class="confluenceTd"></td><br>        </tr><br>        <tr><br>            <td colspan="1" class="confluenceTd"><span>10.1.61.10</span></td><br>            <td colspan="1" class="confluenceTd"><span>4核</span></td><br>            <td colspan="1" class="confluenceTd">24G</td><br>            <td colspan="1" class="confluenceTd"></td><br>        </tr><br>        <tr><br>            <td colspan="1" class="confluenceTd">10.1.53.39</td><br>            <td colspan="1" class="confluenceTd"><span>4核</span></td><br>            <td colspan="1" class="confluenceTd">16G</td><br>            <td colspan="1" class="confluenceTd"></td><br>            <td colspan="1" class="confluenceTd">指标库、ES、租户等组件</td><br>            <td colspan="1" class="confluenceTd">该机器主要用来部署指标库</td><br>        </tr><br>        <tr><br>            <td class="confluenceTd">10.1.61.117</td><br>            <td colspan="1" class="confluenceTd">4核</td><br>            <td class="confluenceTd">16G</td><br>            <td colspan="1" class="confluenceTd">38G</td><br>            <td colspan="1" class="confluenceTd">kairosdb、omp等</td><br>            <td colspan="1" class="confluenceTd"><span>kairosdb 堆内存为默认的3g</span></td><br>        </tr><br>        <tr><br>            <td class="confluenceTd">10.1.61.118</td><br>            <td colspan="1" class="confluenceTd">4核</td><br>            <td class="confluenceTd">16G</td><br>            <td colspan="1" class="confluenceTd">38G</td><br>            <td colspan="1" class="confluenceTd">Cassandra</td><br>            <td colspan="1" class="confluenceTd"><p><span>kairosdb 堆内存为<span>为默认的4</span>g，</span></p><br>                <p>计算公式 max(min(1/2 ram, 1024MB),min(1/4 ram, 8GB))</p></td><br>        </tr><br>        </tbody><br>    </table><br></div><br><p></p><br><h2 id="id-指标库性能测试-三、测试方法">三、测试方法</h2><br><p>测试工具为Jmeter，通过调用指标库相应的openApi测试，用jconsole 监控进程占用资源变化。</p><br><h2 id="id-指标库性能测试-四、测试结果">四、测试结果</h2><h4 id="id-指标库性能测试-写:">写:</h4><br><p style="margin-left: 30.0px;"><span>Ramp-up Period <span>决定多长时间启动所有线程。如果使用10个线程，ramp-up period是100秒，那么JMeter用100秒使所有10个线程启动并运行。每个线程会在上一个线程启动后10秒（100/10）启动。</span></span><br></p><br><p style="margin-left: 30.0px;">monitor 指标上报的频率是15S一次，故此处从 以15S/s 的频率启动一个上报线程开始测试。</p><br><p style="margin-left: 30.0px;">如组1，测试逻辑为：</p><br><p style="margin-left: 60.0px;">每15秒启动一个线程，单个线程每次上报25个指标，重复上报500次，每分钟指标写入请求次数为5W条。</p><br><p style="margin-left: 60.0px;">jmeter-server为1，表示只在本机运行测试；若为4，表示在4个机器上同时对指标库发起请求测试。</p><br><p style="margin-left: 30.0px;"></p><br><p></p><br><p></p><br><p style="margin-left: 30.0px;">1.kairosdb 自带写入统计指标：</p><br><p style="margin-left: 60.0px;">kairosdb.metric_counters - Counts the number of data points received since the last<br>    report. Tags are used to separate one metric from another.（统计自上次上报后接收的数据量。标签用于区分指标。）</p><br><p style="margin-left: 60.0px;"></p><br><p style="margin-left: 30.0px;">kairosdb 统计结果：</p><br><p style="margin-left: 30.0px;"><br><img src="/2017/12/10/171210/kairosdb_metric_count.png"><br><br></p><br><p style="margin-left: 30.0px;">“1”处为组别12的测试结果，“2”处为直接调用kairosdb restApi 写入接口，“3”处为组别14 的结果。结果与指标库的统计日志一致。<br><br></p><p style="margin-left: 30.0px;">2.时间有限，每组测试时间间隔较短，因此可能会对CPU、内存以及Cassandra状态产生影响，使结果不够准确。</p><br><p style="margin-left: 30.0px;"></p><br><p style="margin-left: 30.0px;"><strong>注：</strong></p><br><p style="margin-left: 30.0px;">【1】：指标库redis 报内存不够，异常： Can’t save in background: fork: Cannot allocate memory</p><br><p style="margin-left: 30.0px;">【2】：<span style="background-color: transparent;">短时间插入大量指标会导致未压实的sstable数据太多，压实进程报可用磁盘空间不足，重新压实…恶性循环。</span><br></p><br><p style="margin-left: 30.0px;"><span style="background-color: transparent;"><br></span></p><br><div class="code panel pdl" style="border-width: 1px;"><br>    <div class="codeContent panelContent pdl"><br><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;![CDATA[[root@localhost data_points-1e09be40c3c811e7977aa147ea7baf03]# /opt/cassandra/bin/nodetool compactionstats -H</span><br><span class="line">pending tasks: 2</span><br><span class="line">- kairosdb.data_points: 2</span><br><span class="line">id                                   compaction type keyspace table       completed total    unit  progress</span><br><span class="line">ef340e00-d4d8-11e7-a239-0d717928a22e Compaction      kairosdb data_points 6.23 GB   11.42 GB bytes 54.56%</span><br><span class="line">Active compaction remaining time :   0h05m32s</span><br><span class="line">]]&gt;</span><br></pre></td></tr></table></figure><br><br>    </div><br></div><br><p style="margin-left: 30.0px;"><span><br></span></p><br><p style="margin-left: 30.0px;"><span>Cassandra报异常:</span></p><br><div class="code panel pdl" style="border-width: 1px;"><br>    <div class="codeContent panelContent pdl"><br><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;![CDATA[WARN  [CompactionExecutor:46] 2017-11-28 22:26:29,785 CompactionTask.java:91 - insufficient space to compact all requested files BigTableReader(path=&amp;#39;/opt/dbdata/cassandra/data/kairosdb/data_points-1e09be40c3c811e7977aa147ea7baf03/ma-216-big-Data.db&amp;#39;), BigTableReader(path=&amp;#39;/opt/dbdata/cassandra/data/kairosdb/data_points-1e09be40c3c811e7977aa147ea7baf03/ma-237-big-Data.db&amp;#39;)</span><br><span class="line">ERROR [CompactionExecutor:46] 2017-11-28 22:26:29,827 CassandraDaemon.java:195 - Exception in thread Thread[CompactionExecutor:46,1,main]</span><br><span class="line">java.lang.RuntimeException: Not enough space for compaction, estimated sstables = 1, expected write size = 2395303467</span><br><span class="line">at org.apache.cassandra.db.compaction.CompactionTask.checkAvailableDiskSpace(CompactionTask.java:278) ~[apache-cassandra-3.5.jar:3.5]</span><br><span class="line">at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:126) ~[apache-cassandra-3.5.jar:3.5]</span><br><span class="line">at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-3.5.jar:3.5]</span><br><span class="line">at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:82) ~[apache-cassandra-3.5.jar:3.5]</span><br><span class="line">at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:60) ~[apache-cassandra-3.5.jar:3.5]</span><br><span class="line">at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:264) ~[apache-cassandra-3.5.jar:3.5]</span><br><span class="line">at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_144]</span><br><span class="line">at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_144]</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[na:1.8.0_144]</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_144]</span><br><span class="line">at java.lang.Thread.run(Thread.java:748) [na:1.8.0_144]</span><br><span class="line"></span><br><span class="line">]]&gt;</span><br></pre></td></tr></table></figure><br><br>    </div><br></div><br><p></p><br><p style="margin-left: 30.0px;">解决方法：</p><br><p style="margin-left: 60.0px;">1、增大磁盘空间、</p><br><p style="margin-left: 60.0px;">2、直接删除同一编号的sstable 大文件</p><br><p style="margin-left: 60.0px;">3、重装Cassandra</p><h4 id="id-指标库性能测试-多节点写:">多节点写:</h4><br><p style="margin-left: 30.0px;">1.通过观察发现，写的瓶颈在指标库的gateway，然后增加多节点的测试如下：</p><br><ul><br>    <li style="margin-left: 30.0px;">开启一个gateway、一个writer模块后，指标写入能力在 <strong>50W/分钟</strong>；</li><br>    <li style="margin-left: 30.0px;">开启三个gateway、一个writer模块后，指标写入能力在 <strong>80W/分钟</strong>；</li><br>    <li style="margin-left: 30.0px;">开启三个三个gateway、三个writer 模块后，指标写入能力在 <strong>85W/分钟</strong>。</li><br></ul><br><br><p><br><img src="/2017/12/10/171210/kairosdb_metric_count_70W_75W.png"><br><br></p><p style="margin-left: 30.0px;">2.当部署Cassandra集群（3个节点）后，指标写入能力可以再次提升，<span style="background-color: transparent;">开启三个gateway、一个writer模块，指标写入能力在 <strong>100W/分钟</strong> ，此状态下可持续写入四个小时，期间redis会报内存不够的异常。</span><br></p>&lt;p style=”margin-left: 30.0px; &gt;<br><br><br><p></p><p style="margin-left: 30.0px;"><span style="background-color: transparent;">另外，当指标库写入在满载的情况下，指标的读取能力会受到很大影响，且写入也会偶尔报连接超时现象。</span><br></p><br><p style="margin-left: 30.0px;"><span style="background-color: transparent;"><br></span></p><h4 id="id-指标库性能测试-读："><br>    读：</h4><br><p>指标的查询，其实是kairosdb去查Cassandra中数据。因此kairosdb查Cassandra的速度才是关键因素。而查Cassandra数据的速度，跟查询的Cassandra的row数量、元数据量等因素相关。</p><br><p>要模拟读取测试，就需要先调查现场实际查询的row和元数据大小。</p><br><p>统计局的统计如下：</p><br><p style="margin-left: 30.0px;">上图为密集查询30分钟内指标时，从Cassandra中查询的row的行数；</p><br><p style="margin-left: 30.0px;">中图为密集查询30分钟内指标时，从Cassandra中查询的元数据的数量；</p><br><p style="margin-left: 30.0px;">下图为定时查询时row的行数。</p><br><p><br><br></p><br><p style="margin-left: 30.0px;"><br><img src="/2017/12/10/171210/统计局_query_row_count2.png"><br><br></p><br><p style="margin-left: 30.0px;"></p><br><p style="margin-left: 30.0px;"><br><img src="/2017/12/10/171210/统计局_query_sample_size.png"><br><br></p><br><p style="margin-left: 30.0px;"></p><br><p style="margin-left: 30.0px;"><br><img src="/2017/12/10/171210/统计局_query_row_count.png"><br><br></p><br><p style="margin-left: 30.0px;"></p><br><p style="margin-left: 30.0px;"></p><br><p style="margin-left: 30.0px;">可以看出：</p><br><p style="margin-left: 30.0px;">密集查询时，row最大的在4000，大部分比较小，接近1。定时查询时，row在100行以下。</p><br><p style="margin-left: 30.0px;">现场400个设备，查询30分钟指标时，理论上应该有大约400<em>4</em>30=48000 的元数据，实际查询时，要小于该值。基本都在几百条。</p><br><p></p><br><p></p><p></p><p style="margin-left: 30.0px;">过程：</p><p></p><ol><br>    <li>可以看到单Cassandra节点下，kairosdb查询Cassandra最短耗时已经在2S左右，而集群模式下，kairosdb查询Cassandra的最短耗时在200ms<br>        左右，可以看出在低硬件配置下，Cassandra部署集群模式比单机模式的性能提升很大。<br>    </li><br>    <li>Cassandra刚部署时，查询性能表现优秀，连续写入一个小时数据后，查询性能下降。</li><br>    <li>2-5组发现kairosdb 查询时间正常， 但指标库查询出现超时，经建飞排查，原因是调用kairosdb client时创建的 http连接 最大数量最2，修改为200后，情况好转。<br><br><br><br>  <img src="/2017/12/10/171210/image2017-12-8_11_24_9.png"><br><br>    </li><br>    <li>从测试过程可以看到，部分指标库的查询耗时比kairosdb查Cassandra的耗时长很多，查询kairosdb.datastore.queries_waiting<br>        指标，发现kairosdb存在大量等待线程。如下：<br><br><br><br><img src="/2017/12/10/171210/kairosdb.datastore.queries_waiting.png"><br><br>          <br>修改<br>        kairosdb 的配置：kairosdb.datastore.concurrentQueryThread ，再次查询，依然会有等待的查询线程。<br>据此判断，当查询15个指标时，每个指标耗时在2.5S左右时，此硬件配置下的kairosdb性能已达瓶颈，影响因素为CPU核数。当更改部署kairosdb<br>        机器的核数后，性能得到了提升。<br>    </li><br>    <li>同样的查询条件下，CPU核数与kairosdb 的concurrentQueryThread 参数一致时，性能最优；且该参数只在kairosdb 查Cassandra较慢（2S以上）时，才会产生影响。</li><br></ol><br><h2 id="id-指标库性能测试-五、结论"><br>五、结论</h2><br><h3 id="id-指标库性能测试-1、指标库写性能：">1、指标库写性能：</h3><br><ol><br>    <li>由3、5、6组可知，每分钟请求总量一定的情况下，在未到达瓶颈前，并发线程越多，指标写入量越大。</li><br>    <li>由6、8组可知，本机的机器性能并未成为影响指标写入的因素。</li><br>    <li>由6、7和8、9两组可知，在4核16G单节点Cassandra 配置下，请求数在50W/min 左右时，指标库的gateway 模块接收请求已到达瓶颈，为 <strong>50W /min</strong> 左右。</li><br>    <li>由9、10、11三组可知，在指标写入能力到达瓶颈后，改变并发的线程数，不再产生影响。</li><br>    <li>由9、12组可知，待写入的指标类型量不是影响因素。</li><br>    <li>由15组可知，当指标库写入请求量每分钟到千万级时，会出现redis 内存问题。</li><br>    <li>单指标库、单Cassandra节点下，指标写入能力瓶颈在Cassandra处，为 <strong>80W/min</strong>；<br>多指标库、单Cassandra节点下，指标写入能力瓶颈在Cassandra处，为<br>        <strong>85W/min</strong>；<br>单指标库、多Cassandra节点下，指标写入能力瓶颈为 <strong>100W/min</strong>；<br>多指标库、多Cassandra节点下，指标写入能力瓶颈为<strong><br>            <strong>110W/min</strong></strong>。<br><br><br></li><br></ol><br><p></p><br><p>配置预估：</p><br><p style="margin-left: 30.0px;">假设现场1个资源每15 S上报100个指标，则每分钟上报400个，若采用单节点Cassandra<br>    配置，在redis集群状况良好的情况下，可支持1750个资源左右，考虑到稳定性可酌情减少资源量或增加配置。</p><br><p style="margin-left: 30.0px;"></p><br><h3 id="id-指标库性能测试-2、指标库读性能：">2、指标库读性能：</h3><br><ol><br>    <li>由1、2组可知R12版本指标库在现有配置下，最多支持每分钟30次的查询。</li><br>    <li>由2、3组可知，查询较慢时，每10S钟查询10次，比每5S钟查询5次，查询要快。</li><br>    <li>由2、4组可知，相同的请求量下，同一个指标密集查询2次，比两个指标同时各查一次要慢很多。</li><br>    <li>由1、5组可知，查询的数据量从600到7200，查询的Cassandra row从 77到740，查询耗时基本没有变化，不过Cassandra的资源消耗增加很多。</li><br>    <li>由2、7组可知，kairosdb client 创建的 http连接 最大数量与查询性能十分相关，R13中已调整该参数为200。</li><br>    <li>由6-8、14、15组可知，单Cassandra节点下，指标查询的瓶颈为 <strong>90次/分钟</strong>，且当 指标库的查询耗时 与<br>        kairosdb查Cassandra的耗时相差不大时，可以维持稳定查询状态，否则指标库查询超时会越来越严重。<br>    </li><br>    <li>由8-13、17-19组可知，kairosdb的concurrentQueryThread 参数值与CPU核数一致时，性能最优；且该参数只在kairosdb 查Cassandra较慢（2S以上）时，才会产生影响。</li><br>    <li>由8、16组可知，指标库是否集群模式不是瓶颈。</li><br>    <li>由19、22和20、23两组可知，单kairosdb 8核的查询性能 与双kairosdb 4核基本相同，所以kairosdb 的查询性能与机器的CPU核数有关。</li><br>    <li>由19、24组可知，当前的查询瓶颈在Cassandra 处，Cassandra 集群的查询性能是单节点的10倍。</li><br>    <li>由24-29组可知，Cassandra集群下，查询性能瓶颈为<strong>1400次/分钟</strong>，当查询到1500次/分钟时，kairosdb出现瓶颈，等待查询线程不断增加。</li><br>    <li>由30、31组可知，当Cassandra写入一段时间数据后，指标查询性能下降很多。</li><br></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;*本文是从公司内网KB转过来的，格式有点混乱懒得改了QAZ~~&lt;/p&gt;
&lt;h2 id=&quot;目录-Table-of-Contents&quot;&gt;&lt;a href=&quot;#目录-Table-of-Contents&quot; class=&quot;headerlink&quot; title=&quot; 目录 (Table of
      
    
    </summary>
    
      <category term="未分类" scheme="https://jasonsonghoho.github.io/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/"/>
    
    
      <category term="cassandra" scheme="https://jasonsonghoho.github.io/public/tags/cassandra/"/>
    
      <category term="kairosdb" scheme="https://jasonsonghoho.github.io/public/tags/kairosdb/"/>
    
      <category term="jmeter" scheme="https://jasonsonghoho.github.io/public/tags/jmeter/"/>
    
  </entry>
  
  <entry>
    <title>linux 进程 性能监控</title>
    <link href="https://jasonsonghoho.github.io/2017/11/08/171108/"/>
    <id>https://jasonsonghoho.github.io/2017/11/08/171108/</id>
    <published>2017-11-08T14:08:41.000Z</published>
    <updated>2018-09-20T15:46:06.026Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>进行性能测试，需要统计 kairosdb 的性能随时间的变化情况。</p><h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>考虑过以下方法<br>sar 命令：可以检测机器的各项性能，但不能看进程的性能占用信息<br>top：可以监控到进程的性能信息，但没有趋势图<br>jvisualvm：可以监控到进程的性能信息，有趋势图；但可监控的时间范围受限、不能统计各项状态信息。如下：</p><img src="/2017/11/08/171108/19_14_27.png" title="jvisualvm"><p>最终发现jconsole 可以完美实现这个需求。之前只是感觉jconsoleg功能不如jvisualvm强大，所以没有去看…</p><h2 id="jconsole-使用方法："><a href="#jconsole-使用方法：" class="headerlink" title="jconsole 使用方法："></a>jconsole 使用方法：</h2><ol><li><p>修改远程机器JDK配置文件 (我这里远程机器是linux).<br>a.进入JAVA_HOME\jre\lib\management\目录<br>b.拷贝jmxremote.password.template这个文件到当前目录, 并改名为 jmxremote.password<br>  c.打开jmxremote.password文件，去掉 # monitorRole  QED 和 # controlRole  R&amp;D 这两行前面的注释符号</p></li><li><p>修改远程机器上需要被监控的程序的启动脚本：</p><p> <code>JAVA_OPTS=&quot;-Djava.rmi.server.hostname=10.1.61.117 -Dcom.sun.management.jmxremote.port=18999  -Dcom.sun.management.jmxremote.ssl=false  -Dcom.sun.management.jmxremote.authenticate=false&quot;</code></p><p> 启动脚本 的java 命令后加上 $JAVA_OPTS 参数。</p></li><li><p>本地建立连接，如下：</p></li></ol><img src="/2017/11/08/171108/19_23_5.png" title="本地建立连接"><p>界面如下：</p><img src="/2017/11/08/171108/19_28_49.png" title="界面"><p>更多功能可自行尝试</p><p>可以保存统计数据 到本地(CSV 文件)，如下：</p><img src="/2017/11/08/171108/19_29_20.png" title="保存统计数据"><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>需求解决 （真是踏破铁鞋无觅处…）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;进行性能测试，需要统计 kairosdb 的性能随时间的变化情况。&lt;/p&gt;
&lt;h2 id=&quot;分析&quot;&gt;&lt;a href=&quot;#分析&quot; class=
      
    
    </summary>
    
      <category term="Linux" scheme="https://jasonsonghoho.github.io/categories/Linux/"/>
    
    
      <category term="踩坑记" scheme="https://jasonsonghoho.github.io/public/tags/%E8%B8%A9%E5%9D%91%E8%AE%B0/"/>
    
      <category term="java" scheme="https://jasonsonghoho.github.io/public/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Dubbo Telnet 命令</title>
    <link href="https://jasonsonghoho.github.io/2017/10/23/171023/"/>
    <id>https://jasonsonghoho.github.io/2017/10/23/171023/</id>
    <published>2017-10-23T14:08:41.000Z</published>
    <updated>2018-09-22T02:45:28.893Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录-Table-of-Contents"><a href="#目录-Table-of-Contents" class="headerlink" title=" 目录 (Table of Contents)"></a> <strong>目录 (Table of Contents)</strong></h2><div class="markdown-toc editormd-markdown-toc"><ul class="markdown-toc-list"><li><a class="toc-level-2" href="#login" level="2">login</a></li><li><a class="toc-level-2" href="#status" level="2">status</a></li><li><a class="toc-level-2" href="#ls" level="2">ls</a></li><li><a class="toc-level-2" href="#ps" level="2">ps</a></li><li><a class="toc-level-2" href="#trace" level="2">trace</a></li><li><a class="toc-level-2" href="#invoke" level="2">invoke</a></li><li><a class="toc-level-2" href="#more" level="2">more</a><ul></ul></li></ul></div><blockquote><p>从 2.0.5 版本开始，dubbo 开始支持通过 telnet 命令来镜像服务治理。</p></blockquote><h2 id="login"><a href="#login" class="headerlink" title="login"></a>login</h2><p>telnet localhost 20880(dubbo或服务端口)</p><img src="/2017/10/23/171023/login.png" title="login"><h2 id="status"><a href="#status" class="headerlink" title="status"></a>status</h2><ol><li>status: 显示汇总状态，该状态将汇总所有资源的状态，当全部 OK 时则显示 OK，只要有一个 ERROR 则显示 ERROR，只要有一个 WARN 则显示 WARN</li><li>status -l: 显示状态列表</li></ol><p>见上图</p><h2 id="ls"><a href="#ls" class="headerlink" title="ls"></a>ls</h2><p>显示服务列表、方法列表、参数等</p><ol><li>ls: 显示服务列表</li><li>ls -l: 显示服务详细信息列表</li><li>ls XxxService: 显示服务的方法列表</li><li>ls -l XxxService: 显示服务的方法详细信息列表</li></ol><img src="/2017/10/23/171023/ps&ls.png" title="ls"><h2 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h2><p>显示服务端口列表，可用来查看服务是否已成功注册</p><ol><li>ps: 显示服务端口列表</li><li>ps -l: 显示服务地址列表</li><li>ps 20880: 显示端口上的连接信息</li><li>ps -l 20880: 显示端口上的连接详细信息</li></ol><p>见上图</p><h2 id="trace"><a href="#trace" class="headerlink" title="trace"></a>trace</h2><p>跟踪服务任意方法的调用情况</p><ol><li>trace XxxService: 跟踪 1 次服务任意方法的调用情况</li><li>trace XxxService 10: 跟踪 10 次服务任意方法的调用情况</li><li>trace XxxService xxxMethod: 跟踪 1 次服务方法的调用情况</li><li>trace XxxService xxxMethod 10: 跟踪 10 次服务方法的调用情况</li></ol><img src="/2017/10/23/171023/trace.png" title="trace"><h2 id="invoke"><a href="#invoke" class="headerlink" title="invoke"></a>invoke</h2><p>调用服务的方法，通过该命令可直接调试方法。</p><ol><li>invoke XxxService.xxxMethod({“prop”: “value”}): 调用服务的方法</li><li>invoke xxxMethod({“prop”: “value”}): 调用服务的方法(自动查找包含此方法的服务)</li></ol><img src="/2017/10/23/171023/invoke.png" title="invoke"><h2 id="more"><a href="#more" class="headerlink" title="more"></a>more</h2><p>更多 Dubbo Telnet 命令请参阅：<a href="https://dubbo.gitbooks.io/dubbo-user-book/references/telnet.html" target="_blank" rel="noopener">Telnet 命令参考手册</a> </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录-Table-of-Contents&quot;&gt;&lt;a href=&quot;#目录-Table-of-Contents&quot; class=&quot;headerlink&quot; title=&quot; 目录 (Table of Contents)&quot;&gt;&lt;/a&gt; &lt;strong&gt;目录 (Table of C
      
    
    </summary>
    
      <category term="中间件" scheme="https://jasonsonghoho.github.io/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"/>
    
    
      <category term="dubbo" scheme="https://jasonsonghoho.github.io/public/tags/dubbo/"/>
    
  </entry>
  
  <entry>
    <title>Cassandra 常用命令合集</title>
    <link href="https://jasonsonghoho.github.io/2017/10/22/171022/"/>
    <id>https://jasonsonghoho.github.io/2017/10/22/171022/</id>
    <published>2017-10-22T14:08:41.000Z</published>
    <updated>2018-09-22T02:45:28.889Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录-Table-of-Contents"><a href="#目录-Table-of-Contents" class="headerlink" title=" 目录 (Table of Contents)"></a> <strong>目录 (Table of Contents)</strong></h2><div class="markdown-toc editormd-markdown-toc"><ul class="markdown-toc-list"><li><a class="toc-level-2" href="#修改Cassandra 最大可用内存大小" level="2">修改Cassandra 最大可用内存大小</a></li><li><a class="toc-level-2" href="#登录CQL" level="2">登录CQL</a></li><li><a class="toc-level-2" href="#查看墓碑数据总量" level="2">查看墓碑数据总量</a></li><li><a class="toc-level-2" href="#修复表" level="2">修复表</a></li><li><a class="toc-level-2" href="#压实数据" level="2">压实数据</a></li><li><a class="toc-level-2" href="#查看当前压实操作状态和历史压实纪录" level="2">查看当前压实操作状态和历史压实纪录</a></li><li><a class="toc-level-2" href="#查看表的状态" level="2">查看表的状态</a></li><li><a class="toc-level-2" href="#Cassandra 线程池的使用统计信息" level="2">Cassandra 线程池的使用统计信息</a></li><li><a class="toc-level-2" href="#其他" level="2">其他</a><ul></ul></li></ul></div><blockquote><p>文中Cassandra 安装在/opt 目录下，具体执行命令需根据自己的Cassandra安装目录进行调整。<br>Cassandra 版本为 3.5。</p></blockquote><h2 id="修改Cassandra-最大可用内存大小"><a href="#修改Cassandra-最大可用内存大小" class="headerlink" title="修改Cassandra 最大可用内存大小"></a>修改Cassandra 最大可用内存大小</h2><p>Cassandra 默认最大可用内存和初始内存大小(-Xmx 、-Xms )为 4G ，通常情况下偏小。</p><p>修改最大内存大小可直接修改 cassandra/conf/cassandra-env.sh 中 MAX_HEAP_SIZE 参数：<code>MAX_HEAP_SIZE=&quot;4G&quot;</code></p><p>cassandra 有两种GC策略，系统内存在14G以上，推荐使用 G1策略。默认使用的是CMS策略。参阅<a href="https://docs.datastax.com/en/cassandra/3.0/cassandra/operations/opsTuneJVM.html" target="_blank" rel="noopener">Tuning Java resources </a></p><h2 id="登录CQL、查看版本"><a href="#登录CQL、查看版本" class="headerlink" title="登录CQL、查看版本"></a>登录CQL、查看版本</h2><p>登录：<br><code>/opt/cassandra/bin/cqlsh [ip] -u [username] -p [passwd]</code></p><p>查看版本：<br><code>cqlsh&gt;show version</code></p><img src="/2017/10/22/171022/logIn_showVersion.png" title="登录CQL、查看版本"><h2 id="查看墓碑数据总量"><a href="#查看墓碑数据总量" class="headerlink" title="查看墓碑数据总量"></a>查看墓碑数据总量</h2><p>没有直接查看墓碑数量的好方法，可在CQL 中开启tracing，执行查询时，会提示具体表含有多少墓碑数据：</p><img src="/2017/10/22/171022/count_tombstone.png" title="墓碑数据总量"><h2 id="修复表"><a href="#修复表" class="headerlink" title="修复表"></a>修复表</h2><p>修复表可以手动同步各个节点的数据（包括墓碑数据），需在各个节点分别执行</p><p><code>/opt/cassandra/bin/nodetool  repair kairosdb string_index;</code></p><h2 id="压实数据"><a href="#压实数据" class="headerlink" title="压实数据"></a>压实数据</h2><p>墓碑数据过多会影响Cassandra性能。压实数据，可消除墓碑数据。压实前，需进行表数据的修复，以防删除数据恢复。</p><ol><li>手动压实：</li></ol><p><code>/opt/cassandra/bin/nodetool  compact  kairosdb string_index</code></p><ol start="2"><li><p>开启自动压实(默认已开启)：<code>/opt/cassandra/bin/nodetool enableautocompaction</code></p></li><li><p>修改表的压实策略：</p></li></ol><p><code>ALTER TABLE kairosdb.string_index   WITH compaction =   {&#39;class&#39; : &#39;SizeTieredCompactionStrategy&#39;, &#39;min_threshold&#39; : 6 };</code></p><ol start="4"><li>修改自动压实周期：</li></ol><p>默认压实时间为864000，即10天，修改为一天：<code>alter table kairosdb.string_index with GC_GRACE_SECONDS = 86400;</code></p><p>关于压实策略，请参阅：<a href="https://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlHowDataMaintain.html" target="_blank" rel="noopener">How is data maintained</a></p><h2 id="查看当前压实操作状态和历史压实纪录"><a href="#查看当前压实操作状态和历史压实纪录" class="headerlink" title="查看当前压实操作状态和历史压实纪录"></a>查看当前压实操作状态和历史压实纪录</h2><p><code>/opt/cassandra/bin/nodetool  compactionstats;/opt/cassandra/bin/nodetool  compactionhistory;</code></p><img src="/2017/10/22/171022/compaction.png" title="compaction"><h2 id="查看表的状态"><a href="#查看表的状态" class="headerlink" title="查看表的状态"></a>查看表的状态</h2><p><code>/opt/cassandra/bin/nodetool  cfstats kairosdb.data_points  或/opt/cassandra/bin/nodetool  tablestats kairosdb.data_points;</code></p><img src="/2017/10/22/171022/cfstats.png" title="cfstats"><h2 id="Cassandra-线程池的使用统计信息"><a href="#Cassandra-线程池的使用统计信息" class="headerlink" title="Cassandra 线程池的使用统计信息"></a>Cassandra 线程池的使用统计信息</h2><p>Cassandra基于分阶段事件驱动架构（SEDA）。Cassandra将不同的任务分成由消息服务连接的很多阶段。每个阶段都有一个队列和一个线程池。如果下一个阶段太忙，Cassandra会备份队列，并将导致性能瓶颈。</p><p><code>/opt/cassandra/bin/nodetool tpstats;</code></p><img src="/2017/10/22/171022/tpstats.png" title="tpstats"><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>更多 cassandra命令请参阅：<a href="https://docs.datastax.com/en/cassandra/3.0/cassandra/tools/toolsNodetool.html" target="_blank" rel="noopener">The nodetool utility</a> 、<a href="https://docs.datastax.com/en/cassandra/3.0/index.html" target="_blank" rel="noopener">Apache Cassandra</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录-Table-of-Contents&quot;&gt;&lt;a href=&quot;#目录-Table-of-Contents&quot; class=&quot;headerlink&quot; title=&quot; 目录 (Table of Contents)&quot;&gt;&lt;/a&gt; &lt;strong&gt;目录 (Table of C
      
    
    </summary>
    
      <category term="数据库" scheme="https://jasonsonghoho.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="cassandra" scheme="https://jasonsonghoho.github.io/public/tags/cassandra/"/>
    
      <category term="cql" scheme="https://jasonsonghoho.github.io/public/tags/cql/"/>
    
  </entry>
  
  <entry>
    <title>记一次store 指标库 线上故障的排查</title>
    <link href="https://jasonsonghoho.github.io/2017/09/28/170928/"/>
    <id>https://jasonsonghoho.github.io/2017/09/28/170928/</id>
    <published>2017-09-28T14:08:41.000Z</published>
    <updated>2018-09-20T15:23:28.336Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录-Table-of-Contents"><a href="#目录-Table-of-Contents" class="headerlink" title=" 目录 (Table of Contents)"></a> <strong>目录 (Table of Contents)</strong></h2><div class="markdown-toc editormd-markdown-toc"><ul class="markdown-toc-list"><li><a class="toc-level-2" href="#环境" level="2">环境</a></li><li><a class="toc-level-2" href="#问题&amp;分析&amp;解决" level="2">问题&amp;分析&amp;解决</a><ul><li><a class="toc-level-4" href="#问题1" level="4">问题1</a></li><li><a class="toc-level-4" href="#分析" level="4">分析</a></li><li><a class="toc-level-4" href="#解决" level="4">解决</a></li><li><a class="toc-level-4" href="#问题2" level="4">问题2</a></li><li><a class="toc-level-4" href="#分析" level="4">分析</a></li><li><a class="toc-level-4" href="#解决" level="4">解决</a></li><li><a class="toc-level-4" href="#其他问题" level="4">其他问题</a></li><li><a class="toc-level-4" href="#分析&amp;解决" level="4">分析&amp;解决</a></li></ul></li><li><a class="toc-level-2" href="#其他" level="2">其他</a></li><li><a class="toc-level-2" href="#资料" level="2">资料</a><ul></ul></li></ul></div><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>统计局，三个节点配置一样：</p><ul><li>内存：500+G</li><li>CPU：4*13 core</li></ul><p>Cassandra 、kaiorsdb  、指标库都是以集群模式部署在三台机器上。</p><h2 id="问题-amp-分析-amp-解决"><a href="#问题-amp-分析-amp-解决" class="headerlink" title="问题&amp;分析&amp;解决"></a>问题&amp;分析&amp;解决</h2><h4 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h4><p>统计局 monitor线上环境 统计报表和仪表盘部分加载缓慢，加载时间在8秒左右。</p><img src="/2017/09/28/170928/load_time.png" title="加载时间1"><h4 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h4><p>首先看了指标库的reader 模块日志，发现query 大量timeout异常。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">17-09-22 14:12:29.208 WARN  [DubboServerHandler-10.6.143.124:7513-thread-576] [c.a.d.rpc.filter.TimeoutFilter]  [DUBBO] invoke time out. method: queryarguments: [e10adc3949ba59abbe56e057f20f88dd, DatapointQuery&#123;metric=&apos;system.mem.pct_usage&apos;, time=DatapointQueryTime&#123;start=1506060435275, end=1506060735275, interval=1, interval_unit=&apos;seconds&apos;, aggregator=AVG, align_start_time=false, align_sampling=false&#125;, tags=&#123;tenantId=e10adc3949ba59abbe56e057f20f88dd&#125;, groupBy=DatapointQueryGroupBy&#123;tagKeys=[object]&#125;, useCache=false&#125;] , url is dubbo://10.6.143.124:7513/uyun.indian.reader.api.ReaderService?anyhost=true&amp;application=indian-reader&amp;default.accepts=1000&amp;default.threadpool=cached&amp;default.threads=500&amp;default.timeout=5000&amp;dubbo=2.8.4.170831&amp;generic=false&amp;interface=uyun.indian.reader.api.ReaderService&amp;methods=queryByResId,query,queryAllMetrics,queryTags&amp;pid=20707&amp;revision=api&amp;serialization=kryo&amp;side=provider&amp;timestamp=1505982696415, invoke elapsed 6361 ms., dubbo version: 2.8.4.170831, current host: 10.6.143.124</span><br><span class="line">17-09-22 14:13:00.201 WARN  [DubboServerHandler-10.6.143.124:7513-thread-568] [c.a.d.rpc.filter.TimeoutFilter]  [DUBBO] invoke time out. method: queryAllMetricsarguments: [e10adc3949ba59abbe56e057f20f88dd] , url is dubbo://10.6.143.124:7513/uyun.indian.reader.api.ReaderService?anyhost=true&amp;application=indian-reader&amp;default.accepts=1000&amp;default.threadpool=cached&amp;default.threads=500&amp;default.timeout=5000&amp;dubbo=2.8.4.170831&amp;generic=false&amp;interface=uyun.indian.reader.api.ReaderService&amp;methods=queryByResId,query,queryAllMetrics,queryTags&amp;pid=20707&amp;revision=api&amp;serialization=kryo&amp;side=provider&amp;timestamp=1505982696415, invoke elapsed 6939 ms., dubbo version: 2.8.4.170831, current host: 10.6.143.124</span><br></pre></td></tr></table></figure><h4 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h4><p>query 使用的 kairosdb的读方法。<a href="https://github.com/kairosdb/kairosdb/wiki/Query-Performance" target="_blank" rel="noopener">kairosdb wiki</a>上指出，当指标的 tag/value 组合太大时，查询时将变得非常缓慢。<br>而monitor报表 每次查询需要汇聚一天的数据。一天的指标数据量和读取时间如下：</p><p>一种解决方法是使用<a href="https://github.com/zachm/tscached" target="_blank" rel="noopener">TScached</a>进行读取，tscached 是kairosdb 的一个缓存代理，加载速度可以是kairosdb的100倍（这是它自己说的，感觉有点夸张了）。<br>指标库之前已经配置过 TScached，后来停用了。重新启用后，报表的加载速度明显加快，不再报超时。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">17-09-28 10:01:26.123 INFO  [reporter-thread-1   ] [u.i.method.elapsedtime.report ] ********************* start report 2017-09-28 09:56:26 to 2017-09-28 10:01:26 *********************</span><br><span class="line">17-09-28 10:01:26.131 INFO  [reporter-thread-1   ] [u.i.method.elapsedtime.report ] methodName=uyun.indian.reader.impl.KairosdbReader, count=320, min=16ms, max=1496ms, avg=116.33ms, median=66.00ms, p75=156.00ms, p95=278.95ms, p99=889.79ms</span><br><span class="line">17-09-28 10:01:26.133 INFO  [reporter-thread-1   ] [u.i.method.elapsedtime.report ] methodName=uyun.indian.reader.impl.ReaderServiceImpl.query, count=592, min=16ms, max=1732ms, avg=105.24ms, median=62.00ms, p75=105.00ms, p95=276.05ms, p99=936.27ms</span><br><span class="line">17-09-28 10:01:26.133 INFO  [reporter-thread-1   ] [u.i.method.elapsedtime.report ] methodName=uyun.indian.reader.impl.ReaderServiceImpl.queryAllMetrics, count=1, min=4ms, max=4ms, avg=4.00ms, median=4.00ms, p75=4.00ms, p95=4.00ms, p99=4.00ms</span><br><span class="line">17-09-28 10:01:26.134 INFO  [reporter-thread-1   ] [u.i.method.elapsedtime.report ] methodName=uyun.indian.reader.impl.ReaderServiceImpl.queryByResId, count=2, min=2ms, max=40ms, avg=21.00ms, median=21.00ms, p75=40.00ms, p95=40.00ms, p99=40.00ms</span><br><span class="line">17-09-28 10:01:26.134 INFO  [reporter-thread-1   ] [u.i.method.elapsedtime.report ] methodName=uyun.indian.reader.impl.ReaderServiceImpl.queryTags, count=4, min=37ms, max=38ms, avg=37.50ms, median=37.50ms, p75=38.00ms, p95=38.00ms, p99=38.00ms</span><br><span class="line">17-09-28 10:01:26.135 INFO  [reporter-thread-1   ] [u.i.method.elapsedtime.report ] methodName=uyun.indian.reader.impl.TScachedReader, count=272, min=22ms, max=1732ms, avg=91.88ms, median=57.00ms, p75=75.75ms, p95=241.05ms, p99=1092.88ms</span><br><span class="line">17-09-28 10:01:26.135 INFO  [reporter-thread-1   ] [u.i.method.elapsedtime.report ] ********************* end report *********************</span><br></pre></td></tr></table></figure><h4 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h4><p>query 方法速度上来之后，发现queryAllMetrics 方法出现超时现象，按问题1的解决办法处理后，发现仍有问题，后改用读redis 缓存的方式后，暂时解决。<br>但Cassandra的资源消耗仍比较大</p><img src="/2017/09/28/170928/cassandra1.png" title="Cassandra 资源消耗"><img src="/2017/09/28/170928/cassandra2.png" title="Cassandra 资源消耗"><h4 id="分析-1"><a href="#分析-1" class="headerlink" title="分析"></a>分析</h4><p>查看Cassandra system日志后发现 kairosdb.data_points 表中存在大量<a href="https://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlAboutDeletes.html" target="_blank" rel="noopener">tombstone</a>(墓碑)数据警告，严重影响了Cassandra性能。需对Cassandra 进行数据<a href="https://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlHowDataMaintain.html" target="_blank" rel="noopener">compact</a>(压实)操作，以清除墓碑数据。<br>在对数据进行压实操作之前，需要先<a href="https://docs.datastax.com/en/cassandra/3.0/cassandra/operations/opsRepairNodesManualRepair.html" target="_blank" rel="noopener">repair</a>(修复)。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WARN  [SharedPool-Worker-30] 2017-09-26 15:48:50,818 ReadCommand.java:481 - Read 1024 live rows and 22072 tombstone cells for query SELECT value FROM kairosdb.data_points WHERE key = 65313061646333393439626135396162626535366530353766323066383864647e73797374656d2e6e65742e62797465735f72637664000000015dc970d000000d6b6169726f735f646f75626c656465766963653d6962313a686f73743d646d3031646261646d30342e73746174732e676f762e636e3a69703d31302e362e3133342e38303a6f626a6563743d3539383763643931633633396438613830633433653631383a74656e616e7449643d65313061646333393439626135396162626535366530353766323066383864643a AND column1 &gt;= 00000000 AND column1 &lt;= 9dd94 (see tombstone_warn_threshold)</span><br></pre></td></tr></table></figure><blockquote><p>在Cassandra中，一切都是写入，包括逻辑删除数据，当你删除一条数据时，其实是给这条数据进行update，给它update上一个标识，就是一个墓碑标识。 当Cassandra集群在不同节点之间同步删除信息的时候，也会用到Tombstones(墓碑)，可以说墓碑是一种允许Cassandra快速写入的机制。 </p></blockquote><p>关于Cassandra 如何维护数据，可参考  <a href="https://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlHowDataMaintain.html" target="_blank" rel="noopener">Cassandra 数据维护官方文档</a></p><h4 id="解决-1"><a href="#解决-1" class="headerlink" title="解决"></a>解决</h4><p>具体压实步骤如下：</p><ol><li>cassandra 默认压缩周期为10天，首先将压缩周期设为1天，设置 gc_grace_seconds 参数，</li></ol><p>登录Cassandra:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./cqlsh host -u user -p pswd</span><br></pre></td></tr></table></figure><p>设置kairosdb的表的压缩周期设为 一天（86400 s）: </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">alter table kairosdb.string_index with gc_grace_seconds = 86400;alter table kairosdb.data_points with GC_GRACE_SECONDS = 86400;alter table kairosdb.row_key_index with GC_GRACE_SECONDS = 86400;</span><br><span class="line"></span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">设置完后 ，运行`DESC kairosdb;`，可以看到 **gc_grace_seconds**已被设为86400；</span><br></pre></td></tr></table></figure><p>CREATE TABLE kairosdb.string_index (<br>    key blob,<br>    column1 text,<br>    value blob,<br>    PRIMARY KEY (key, column1)<br>) WITH COMPACT STORAGE<br>    AND CLUSTERING ORDER BY (column1 ASC)<br>    AND bloom_filter_fp_chance = 0.01<br>    AND caching = {‘keys’: ‘ALL’, ‘rows_per_partition’: ‘NONE’}<br>    AND comment = ‘’<br>    AND compaction = {‘class’: ‘org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy’, ‘max_threshold’: ‘32’, ‘min_threshold’: ‘4’}<br>    AND compression = {‘chunk_length_in_kb’: ‘64’, ‘class’: ‘org.apache.cassandra.io.compress.LZ4Compressor’}<br>    AND crc_check_chance = 1.0<br>    AND dclocal_read_repair_chance = 0.1<br>    AND default_time_to_live = 0<br>     AND gc_grace_seconds = 86400<br>    AND max_index_interval = 2048<br>    AND memtable_flush_period_in_ms = 0<br>    AND min_index_interval = 128<br>    AND read_repair_chance = 1.0<br>    AND speculative_retry = ‘NONE’;</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">2.  为了统一各个节点的墓碑数据，需在各个节点上分别运行修复kairosdb下各个表，防止已删除数据重生;</span><br></pre></td></tr></table></figure><p>nodetool  repair kairosdb row_key_index<br>nodetool  repair kairosdb string_index<br>nodetool  repair kairosdb data_points<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">*此处运行修复时，三个节点的data_points表由于数据太大，一直没有完全修复成功（some repair failed ）。由于数据量较大，且接受删掉的数据再次恢复，此处采取的措施是忽略该表。</span><br><span class="line"></span><br><span class="line">3.  修复完后再分别进行压实操作:</span><br></pre></td></tr></table></figure></p><p>nodetool  compact  kairosdb row_key_index<br>nodetool  compact  kairosdb string_index<br>nodetool  compact  kairosdb data_points<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line">压实操作可用`nodetool  compactionstats` 和 `nodetool  compactionhistory`分别查看当前和历史的压实造作;</span><br><span class="line"></span><br><span class="line">&#123;% asset_img compactionstats.png 压实状态 %&#125;</span><br><span class="line"></span><br><span class="line">4.  开启自动压实操作（默认已开启）：`nodetool enableautocompaction` </span><br><span class="line"></span><br><span class="line">操作完后，Cassandra 会自动压缩一些其他表的数据。结束后，Cassandra 日志中data_points表 墓碑警告记录墓碑数量大幅变小，可以发现Cassandra对资源的占用变到正常水平。 </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### 其他问题</span><br><span class="line"></span><br><span class="line">1.  cassandra 日志报：</span><br><span class="line"></span><br><span class="line">``</span><br><span class="line"> INFO  [IndexSummaryManager:1] 2017-09-28 08:16:56,278 IndexSummaryRedistribution.java:74 - Redistributing index summaries</span><br><span class="line"> INFO  [SharedPool-Worker-1] 2017-09-28 08:19:46,973 NoSpamLogger.java:91 - Maximum memory usage reached (536870912 bytes), cannot allocate chunk of 1048576 bytes</span><br><span class="line">``</span><br><span class="line"></span><br><span class="line">2.  Dubbo 消费者报：No provider available for the service。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### 分析&amp;解决</span><br><span class="line"></span><br><span class="line">1.  调查得知，原因是file_cache_size_in_mb较小，文档中描述该参数是用来读[SSTables](https://stackoverflow.com/questions/2576012/what-is-an-sstable)(Sorted Strings Table , is a file of key/value string pairs, sorted by keys)的缓冲区：</span><br><span class="line">&gt;file_cache_size_in_mb :(Default: Smaller of 1/4 heap or 512) Total memory to use for SSTable-reading buffers.</span><br><span class="line"></span><br><span class="line">调到1024 （M）后，不再报该问题</span><br><span class="line"></span><br><span class="line">2.  服务注册不到zookeeper 上，猜测可能是机器IO负载太大。</span><br><span class="line">执行`netstat -nat | awk &apos;&#123;print $6&#125;&apos; | sort | uniq -c | sort -n` ，可以看到 CLOSE_WAIT 连接太多：</span><br></pre></td></tr></table></figure></p><p>[root@Uyun-DB2 logs]# netstat -nat | awk ‘{print $6}’ | sort | uniq -c | sort -n<br>      1 established)<br>      1 Foreign<br>      2 TIME_WAIT<br>     47 LISTEN<br>   1088 ESTABLISHED<br>   3314 CLOSE_WAIT<br><code>`</code></p><p><code>netstat -nat | grep CLOSE_WAIT</code> 后，发现是kairosdb 造成的（猜测是之前Cassandra负载太大造成 ），强行重启kairosdb 后，再启动指标库，服务正常。</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ol><li><p>kairosDB 作者建议采用<a href="https://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlHowDataMaintain.html#dmlHowDataMaintain__dtcs-compaction" target="_blank" rel="noopener">DateTieredCompactionStrategy</a> (DTCS)压实策略，参考 <a href="https://github.com/kairosdb/kairosdb/issues/23" target="_blank" rel="noopener">kairosDB Issue 23</a>。需要进一步研究。</p></li><li><p>还是会有 Cassandra 占CPU较高的现象，但日志正常，需要进一步研究。</p></li></ol><h2 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h2><p><a href="https://docs.datastax.com/en/cassandra/3.0/cassandra/dml/dmlHowDataMaintain.html" target="_blank" rel="noopener">Cassandra–How is data maintained</a></p><p><a href="http://blog.csdn.net/nangongyanya/article/details/54018104" target="_blank" rel="noopener">操作Cassandra（3）-合并、压实</a></p><p><a href="http://www.cnblogs.com/didda/p/4728588.html" target="_blank" rel="noopener">Cassandra 的压缩策略STCS，LCS 和 DTCS</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录-Table-of-Contents&quot;&gt;&lt;a href=&quot;#目录-Table-of-Contents&quot; class=&quot;headerlink&quot; title=&quot; 目录 (Table of Contents)&quot;&gt;&lt;/a&gt; &lt;strong&gt;目录 (Table of C
      
    
    </summary>
    
      <category term="数据库" scheme="https://jasonsonghoho.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="cassandra" scheme="https://jasonsonghoho.github.io/public/tags/cassandra/"/>
    
      <category term="kairosdb" scheme="https://jasonsonghoho.github.io/public/tags/kairosdb/"/>
    
      <category term="TScached" scheme="https://jasonsonghoho.github.io/public/tags/TScached/"/>
    
      <category term="linux" scheme="https://jasonsonghoho.github.io/public/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>使用jekyll 搭建一个github page</title>
    <link href="https://jasonsonghoho.github.io/2017/09/24/170924/"/>
    <id>https://jasonsonghoho.github.io/2017/09/24/170924/</id>
    <published>2017-09-24T14:08:41.000Z</published>
    <updated>2018-09-20T15:23:28.312Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录-Table-of-Contents-1"><a href="#目录-Table-of-Contents-1" class="headerlink" title=" 目录 (Table of Contents)1"></a> <strong>目录 (Table of Contents)</strong>1</h2>  <div class="markdown-toc editormd-markdown-toc"><br>      <ul class="markdown-toc-list"><br>          <li><a class="toc-level-2" href="#一-简介" level="2">一 简介:</a></li><br>          <li><a class="toc-level-2" href="#二-GitHub page 是什么？Jekyll 是什么？" level="2">二 GitHub page 是什么？Jekyll 是什么？</a><br>          </li><br>          <li><a class="toc-level-2" href="#三-前提" level="2">三 前提</a></li><br>          <li><a class="toc-level-2" href="#四-GitHub page搭建" level="2">四 GitHub page搭建</a></li><br>          <li><a class="toc-level-2" href="#五-环境搭建步骤" level="2">五 环境搭建步骤</a><br>              <ul><br>                  <li><a class="toc-level-4" href="#安装 Ruby" level="4">安装 Ruby</a></li><br>                  <li><a class="toc-level-4" href="#安装 DevKit" level="4">安装 DevKit</a></li><br>                  <li><a class="toc-level-4" href="#安装 Jekyll" level="4">安装 Jekyll</a></li><br>                  <li><a class="toc-level-4" href="#启动 Jekyll" level="4">启动 Jekyll</a></li><br>              </ul><br>          </li><br>          <li><a class="toc-level-2" href="#六-实用工具" level="2">六 实用工具</a></li><br>          <li><a class="toc-level-2" href="#七-参考" level="2">七 参考</a><br>              <ul></ul><br>          </li><br>      </ul><br>  </div><h2 id="一-简介"><a href="#一-简介" class="headerlink" title="一 简介"></a>一 简介</h2><blockquote><p>相信大家都有过搭建自己的技术博客的想法，但是实现起来却并不是那么容易，<br>个人总结了一下，主要有两方面的原因：</p></blockquote><blockquote><p>1、建站需要购买域名和服务器，对于大多数人来说这应该算是一个基本没有什么收益的不大不小的支出，不太划算。 \<br>2、传统方式搭建一个自己的博客网站太繁琐。</p></blockquote><blockquote><p>基于以上原因，自己实现博客的过程充满阻碍。但是又不甘心于在CSDN、博客园等网站上用固定的博客模板。<br>而本文介绍的方法可以完美解决上述问题，尽管功能上仍有所不足，但已足够强大。</p></blockquote><h2 id="二-GitHub-page-是什么？Jekyll-是什么？"><a href="#二-GitHub-page-是什么？Jekyll-是什么？" class="headerlink" title="二 GitHub page 是什么？Jekyll 是什么？"></a>二 GitHub page 是什么？Jekyll 是什么？</h2><p><a href="https://pages.github.com/" target="_blank" rel="noopener">Github Pages</a> 是面向用户、组织和项目开放的公共静态页面搭建托管服务，站点可以被免费托管在Github 上，你可以选择使用Github Pages 默认提供的域名github.io 或者自定义域名来发布站点。</p><p><a href="http://jekyllcn.com/docs/home" target="_blank" rel="noopener">Jekyll</a> 是一个简单的博客形态的静态站点生产机器。总之就是一个快速搭建web 网站的模板工具。而GitHub page正是基于它实现的。</p><h2 id="三-前提"><a href="#三-前提" class="headerlink" title="三 前提"></a>三 前提</h2><p>搭建GitHub page 首先需要注册一个<a href="https://github.com/" target="_blank" rel="noopener">GitHub 账号</a>，掌握git常用命令，掌握web开发基础知识，了解linux 基本命令，了解markdown基本用法。</p><h2 id="四-GitHub-page搭建"><a href="#四-GitHub-page搭建" class="headerlink" title="四 GitHub page搭建"></a>四 GitHub page搭建</h2><p>首先去注册一个github账号。一个简单的page demo步骤如下：</p><ul><li>登录到Github上，新建一个github项目</li></ul><img src="/2017/09/24/170924/newgit1.png"><ul><li><p><strong>注意项目名必须与你的 github 账户名一致 </strong>，点击create</p><img src="/2017/09/24/170924/newgit2.png"></li><li><p>拷贝项目地址</p><img src="/2017/09/24/170924/newgit3.png"></li><li><p>点击”setting”</p><img src="/2017/09/24/170924/newgit4.png"></li><li><p>找到gitgub page ,检查是否为 master branch</p><img src="/2017/09/24/170924/newgit5.png"></li><li><p>此处使用idea clone git项目，没有idea可使用GitHub bash，参考命令：</p><pre><code class="shell">git initgit add README.mdgit commit -m "first commit"git remote add origin https://github.com/JasonSongHoho/jasonsonghoho.github.io.gitgit push -u origin master</code></pre> </li></ul><img src="/2017/09/24/170924/idea1.png"><ul><li><p>粘贴刚才拷贝的项目地址</p><img src="/2017/09/24/170924/idea2.png"></li><li><p>新建一个html文件，命名为index，内容如图</p><img src="/2017/09/24/170924/idea3.png"></li><li><p>push项目代码</p><img src="/2017/09/24/170924/idea4.png"></li><li><p>登录GitHub 查看 ，代码已提交</p><img src="/2017/09/24/170924/aftgit1.png"></li><li><p>访问 <a href="https://jasonsonghoho.github.io/">https://jasonsonghoho.github.io/</a> jasonsonghoho为你的账户名</p><img src="/2017/09/24/170924/aftgit2.png"></li></ul><h2 id="五-环境搭建步骤"><a href="#五-环境搭建步骤" class="headerlink" title="五 环境搭建步骤"></a>五 环境搭建步骤</h2><p>GitHub page的开发需要使用jekyll，因此，首先需要搭建好jekyll开发环境。这里介绍windows下的搭建步骤，mac 环境或者linux下搭建步骤相似，且出问题的概率更小。</p><h5 id="步骤如下"><a href="#步骤如下" class="headerlink" title="步骤如下:"></a>步骤如下:</h5><ul><li>安装 Ruby </li><li>安装 DevKit </li><li>安装 Jekyll </li><li>启动 Jekyll </li></ul><h4 id="安装-Ruby"><a href="#安装-Ruby" class="headerlink" title="安装 Ruby"></a>安装 Ruby</h4><p>Jekyll是一款基于Ruby的插件，安装Ruby是必须的. </p><ol><li><p>前往 <a href="https://rubyinstaller.org/downloads/" target="_blank" rel="noopener">https://rubyinstaller.org/downloads/</a> , 在 “RubyInstallers” 部分，选择一个版本点击下载，“X86”代表32位机器版本，此处选择了“rubyinstaller-2.2.6-x64”版本。<br>注意，<strong>不要选择低于2.1 版本的</strong>，我在安装jekyll时提示版本不能低于2.1。</p></li><li><p>执行安装包安装，考虑到win10下C盘下的文件访问可能需要管理员权限，安装目录我选择了D盘。<br>注意，<strong>不要使用带有空格的文件夹目录</strong>，勾选 “Add Ruby executables to your PATH”，这样执行程序会被自动添加至 PATH 而避免不必要的麻烦。 </p><img src="/2017/09/24/170924/ruby-install.png"></li><li><p>打开命令提示行 输入 <code>ruby -v</code> </p><pre><code class="shell">C:\Users\JasonSong\Desktop>ruby -vruby 2.2.6p396 (2016-11-15 revision 56800) [x64-mingw32]</code></pre> </li></ol><h4 id="安装-DevKit"><a href="#安装-DevKit" class="headerlink" title="安装 DevKit"></a>安装 DevKit</h4><p>DevKit 是一个在 Windows 上帮助简化安装及使用 Ruby C/C++ 扩展如 RDiscount 和 RedCloth 的工具箱。 详细的安装指南可以在程序的wiki 页面 阅读。</p><ol><li><p>前往 <a href="https://rubyinstaller.org/downloads/" target="_blank" rel="noopener">https://rubyinstaller.org/downloads/</a> ,  下载DevKit 安装包。</p><img src="/2017/09/24/170924/devkit-inst.png"></li><li><p>运行安装包并解压缩至某文件夹，如 D:\DevKit</p><p>通过初始化来创建 config.yml 文件。在命令行窗口内，输入下列命令：</p><pre><code class="shell"> cd “DevKit” ruby dk.rb init ruby dk.rb review ruby dk.rb install</code></pre> </li></ol><h4 id="安装-Jekyll"><a href="#安装-Jekyll" class="headerlink" title="安装 Jekyll"></a>安装 Jekyll</h4><p>确保 gem 已经正确安装</p><pre><code class="shell">gem -vgem install jekyll </code></pre> <h4 id="启动-Jekyll"><a href="#启动-Jekyll" class="headerlink" title="启动 Jekyll"></a>启动 Jekyll</h4><p>按照官方的 Jekyll 快速开始手册 的步骤， 一个新的 Jekyll 博客可以被建立并在localhost:4000浏览。</p><p><pre><code class="shell"><br>jekyll new myblog<br>cd myblog<br>jekyll serve<br> </code></pre><br>可能会遇到服务器没有响应或者 443 等错误，这些都无需担心，多尝试几次就可以。</p><h2 id="六-实用工具"><a href="#六-实用工具" class="headerlink" title="六 实用工具"></a>六 实用工具</h2><ul><li><a href="https://pandao.github.io/editor.md/" target="_blank" rel="noopener">Editor.md</a> 一个开源在线 Markdown 编辑器 </li><li><a href="http://jekyllcn.com/docs/home/" target="_blank" rel="noopener">Jekyll 使用参考</a> </li><li><a href="http://jekyllthemes.org/page2/" target="_blank" rel="noopener">Jekyll 主题</a></li></ul><h2 id="七-参考"><a href="#七-参考" class="headerlink" title="七 参考"></a>七 参考</h2><ul><li><a href="http://www.ruanyifeng.com/blog/2012/08/blogging_with_jekyll.html" target="_blank" rel="noopener">搭建一个免费的，无限流量的Blog—-github Pages和Jekyll入门</a></li><li><a href="http://blog.csdn.net/rainloving/article/details/45745491" target="_blank" rel="noopener">Windows 上安装 Jekyll</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目录-Table-of-Contents-1&quot;&gt;&lt;a href=&quot;#目录-Table-of-Contents-1&quot; class=&quot;headerlink&quot; title=&quot; 目录 (Table of Contents)1&quot;&gt;&lt;/a&gt; &lt;strong&gt;目录 (Table
      
    
    </summary>
    
      <category term="博客" scheme="https://jasonsonghoho.github.io/categories/%E5%8D%9A%E5%AE%A2/"/>
    
    
      <category term="jekyll" scheme="https://jasonsonghoho.github.io/public/tags/jekyll/"/>
    
      <category term="github" scheme="https://jasonsonghoho.github.io/public/tags/github/"/>
    
      <category term="gitgub page" scheme="https://jasonsonghoho.github.io/public/tags/gitgub-page/"/>
    
  </entry>
  
  <entry>
    <title>Spark端口整理</title>
    <link href="https://jasonsonghoho.github.io/2017/06/06/2017-06-06-doc/"/>
    <id>https://jasonsonghoho.github.io/2017/06/06/2017-06-06-doc/</id>
    <published>2017-06-06T14:08:41.000Z</published>
    <updated>2018-09-20T15:24:38.658Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Configuring Ports for Network Security<br>Spark makes heavy use of the network, and some environments have strict requirements for using tight firewall settings. Below are the primary ports that Spark uses for its communication and how to configure those ports.</p></blockquote><h2 id="Standalone-mode-only"><a href="#Standalone-mode-only" class="headerlink" title="Standalone mode only"></a>Standalone mode only</h2><table><thead><tr><th>From    To</th><th style="text-align:center">Default Port</th><th style="text-align:center">Purpose</th><th style="text-align:center">Configuration</th><th style="text-align:center">Setting</th><th style="text-align:center">Notes</th></tr></thead><tbody><tr><td>Browser</td><td style="text-align:center">Standalone Master</td><td style="text-align:center">8080</td><td style="text-align:center">Web UI</td><td style="text-align:center">spark.master.ui.port  SPARK_MASTER_WEBUI_PORT</td><td style="text-align:center">Jetty-based. Standalone mode only.</td></tr><tr><td>Browser</td><td style="text-align:center">Standalone Worker</td><td style="text-align:center">8081</td><td style="text-align:center">Web UI</td><td style="text-align:center">spark.worker.ui.port SPARK_WORKER_WEBUI_PORT</td><td style="text-align:center">Jetty-based. Standalone mode only.</td></tr><tr><td>Driver、 Standalone Worker</td><td style="text-align:center">Standalone Master</td><td style="text-align:center">7077</td><td style="text-align:center">Submit job to cluster Join cluster</td><td style="text-align:center">SPARK_MASTER_PORT</td><td style="text-align:center">Set to “0” to choose a port randomly. Standalone mode only. spark service 端口</td></tr><tr><td>Standalone Master</td><td style="text-align:center">Standalone Worker</td><td style="text-align:center">(random)</td><td style="text-align:center">Schedule executors</td><td style="text-align:center">SPARK_WORKER_PORT</td><td style="text-align:center">Set to “0” to choose a port randomly. Standalone mode only.</td></tr></tbody></table><h2 id="All-cluster-managers"><a href="#All-cluster-managers" class="headerlink" title="All cluster managers"></a>All cluster managers</h2><table><thead><tr><th>From    To</th><th style="text-align:center">Default Port</th><th style="text-align:center">Purpose</th><th style="text-align:center">Configuration</th><th style="text-align:center">Setting</th><th style="text-align:center">Notes</th></tr></thead><tbody><tr><td>Browser</td><td style="text-align:center">History Server</td><td style="text-align:center">4040</td><td style="text-align:center">Web UI</td><td style="text-align:center">spark.master.ui.port</td><td style="text-align:center">Jetty-based. 一个worker上可以有多个Job,因此该端口号会随着job的增加而递增。</td></tr><tr><td>Browser</td><td style="text-align:center">History Server</td><td style="text-align:center">8081</td><td style="text-align:center">Web UI</td><td style="text-align:center">spark.history.ui.port</td><td style="text-align:center">Jetty-based.</td></tr><tr><td>Executor /  Standalone Master</td><td style="text-align:center">Driver</td><td style="text-align:center">(random)</td><td style="text-align:center">Connect to application /Notify executor state changes</td><td style="text-align:center">spark.driver.port</td><td style="text-align:center">Set to “0” to choose a port randomly.</td></tr><tr><td>Standalone Master</td><td style="text-align:center">Executor / Driver</td><td style="text-align:center">(random)</td><td style="text-align:center">Block Manager port</td><td style="text-align:center">spark.blockManager.port</td><td style="text-align:center">Raw socket via ServerSocketChannel</td></tr></tbody></table><p>注：History Server 是需要配置才可以访问的。配置好后访问该服务，能重新渲染生成UI界面展现出该Application在执行过程中的运行时信息。<br>       启用该服务方法可参考 Spark History Server配置使用 和 spark 查看 job history 日志 。</p><h2 id="Spark-UI"><a href="#Spark-UI" class="headerlink" title="Spark UI"></a>Spark UI</h2><table><thead><tr><th>From    To</th><th style="text-align:center">Default</th><th style="text-align:center">Meaning</th></tr></thead><tbody><tr><td>spark.blockManager.port</td><td style="text-align:center">(random)</td><td style="text-align:center">Port for all block managers to listen on. These exist on both the driver and the executors.</td></tr><tr><td>spark.driver.blockManager.port</td><td style="text-align:center">(value of spark.blockManager.port)</td><td style="text-align:center">spark.driver.blockManager.port    (value of spark.blockManager.port)    Driver-specific port for the block manager to listen on, for cases where it cannot use the same configuration as executors.</td></tr><tr><td>spark.driver.port</td><td style="text-align:center">(random)</td><td style="text-align:center">spark.driver.port    (random)    Port for the driver to listen on. This is used for communicating with the executors and the standalone Master.</td></tr></tbody></table><h2 id="Shuffle-Behavior"><a href="#Shuffle-Behavior" class="headerlink" title="Shuffle Behavior"></a>Shuffle Behavior</h2><table><thead><tr><th>Property Name</th><th style="text-align:center">Default</th><th style="text-align:center">Meaning</th></tr></thead><tbody><tr><td>spark.shuffle.service.port</td><td style="text-align:center">7337</td><td style="text-align:center">Port on which the external shuffle service will run.</td></tr></tbody></table><h2 id="Spark隐藏端口"><a href="#Spark隐藏端口" class="headerlink" title="Spark隐藏端口"></a>Spark隐藏端口</h2><p>6066 相关隐藏端口<br>可参考: <a href="http://arturmkrtchyan.com/apache-spark-hidden-rest-api" target="_blank" rel="noopener">apache-spark-hidden-rest-api</a></p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><blockquote><p><a href="https://spark.apache.org/docs/latest/security.html#configuring" target="_blank" rel="noopener">spark doc</a></p><p><a href="https://spark.apache.org/docs/latest/configuration.html" target="_blank" rel="noopener">spark doc2</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;Configuring Ports for Network Security&lt;br&gt;Spark makes heavy use of the network, and some environments have strict requiremen
      
    
    </summary>
    
      <category term="大数据" scheme="https://jasonsonghoho.github.io/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="https://jasonsonghoho.github.io/public/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="spark" scheme="https://jasonsonghoho.github.io/public/tags/spark/"/>
    
  </entry>
  
</feed>
